# -*- coding: utf-8 -*-
"""Consultation_NLP_douane.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nHTcOn-dEwe12FJuxRxLKlqvLD7Icw_O
"""

from IPython import get_ipython
from IPython.display import display
from google.colab import drive
drive.mount('/content/drive')

"""Install libraries to use GPU acceleration for our model."""

!apt-get update -y
!apt-get install -y pciutils lshw
!apt update && apt install -y lsof net-tools

"""Code for the Model File to adapt hyperparameters"""

###For the Model File

FROM gemma3:27b      # ← Adapt if needed

# deterministic generation
PARAMETER temperature 0
# probabilistic filtering (20 % of cumulative probability)
PARAMETER top_p
# keep the 40 most probable tokens
PARAMETER top_k
# to set the model's context window size
PARAMETER num_ctx 20000

# Via the terminal

curl -fsSL https://ollama.com/install.sh | sh

# To start ollama
ollama serve & ollama pull gemma3:27b     # then after "control"+c
ollama serve & ollama pull gemma3:27b    # yes, you have to do it twice in a row for some obscure reason.

#ollama serve & ollama pull llama3.3
#ollama serve & ollama pull llama3.3

#ollama serve & ollama pull qwen3:30b-a3b
#ollama serve & ollama pull qwen3:30b-a3b

# You need to download the modelfile and put it in the root,
# to adapt hyperparameters, temperature, top_k, top_p and especially the context window

ollama create gemma3_det:latest -f Modelfile
ollama serve & ollama pull gemma3_det:latest

#ollama create llama3.3_det -f Modelfile
#ollama serve & ollama pull llama3.3_det

#ollama create qwen3:30b-a3b_det -f Modelfile
#ollama serve & ollama pull qwen3:30b-a3b_det

# pkill ollama to reset the model

"""/content# ollama serve & ollama pull llama3.3
[2] 8371
[GIN] 2025/05/14 - 06:43:10 | 200 |     109.301µs |       127.0.0.1 | HEAD     "/"
Error: listen tcp 127.0.0.1:11434: bind: address already in use
pulling manifest ⠙ [GIN] 2025/05/14 - 06:43:10 | 200 |  298.677892ms |       127.0.0.1 | POST     "/api/pull"
pulling manifest
pulling 4824460d29f2: 100% ▕▏  42 GB                         
pulling 948af2743fc7: 100% ▕▏ 1.5 KB                         
pulling bc371a43ce90: 100% ▕▏ 7.6 KB                         
pulling 53a87df39647: 100% ▕▏ 5.6 KB                         
pulling 56bb8bd477a5: 100% ▕▏   96 B                         
pulling c7091aa45e9b: 100% ▕▏  562 B                         
verifying sha256 digest
writing manifest
success

Depending on the chosen model, adapt the code
"""

model_name   = "gemma3_det:latest"   # ← Adapt if needed

#model_name   = "llama3.3:latest"

#model_name   = "llama3.3_det"

#model_name   = "qwen3:30b-a3b_det"

"""To make sure the model has been "pulled" correctly, we will do a quick test."""

import requests

resp = requests.post(
    "http://localhost:11434/api/generate",
    json={
        "model": "gemma3_det:latest",
        "prompt": """Ping!"""
    }
)

print("HTTP", resp.status_code)  # 200 = OK
print(resp.text[:500])           # displays the first 500 characters

"""Avant de commencer nous allons installer l'ensemble des librairies necessaires au fonctionnement de notre code."""

!pip install ocrmypdf PyPDF2 pdf2image pytesseract
!pip install pikepdf
!apt-get update -qq
!apt-get install -y -qq ghostscript tesseract-ocr
!pip install -q ocrmypdf
!pip install PyPDF2 langdetect
!apt-get update -qq
!apt-get install -y -qq unpaper

import os
import re
from PyPDF2 import PdfWriter
from PyPDF2 import PdfReader
import ocrmypdf
import langdetect
from langdetect import detect_langs, LangDetectException
import matplotlib.pyplot as plt
from pathlib import Path
import subprocess
import pandas as pd
import json
import shutil
from tempfile import template
import unicodedata
import pikepdf
import logging
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import textwrap
import logging

"""First step: We will take the opinion file, OCR it, and then cut it according to each stakeholder"""

# 1.1) To achieve our OCR, we must first "designate" the initial document


in_path  = '/content/drive/MyDrive/Consu_douane/fedlex-data-admin-ch-eli-dl-proj-2023-79-cons_1-doc_7-fr-pdf-a.pdf'
tmp_path = '/content/drive/MyDrive/Consu_douane/unsigned.pdf'

pdf = pikepdf.Pdf.open(in_path)
acro = pdf.Root.get("/AcroForm")
if acro and "/Fields" in acro:
    # ne garder que les champs non-signature
    fields = [f for f in acro.Fields if f.get("/FT") != "/Sig"]
    if fields:
        acro.Fields = fields
    else:
        del pdf.Root.AcroForm
pdf.save(tmp_path)

"""1) OCR on the Opinions PDF"""

input_pdf  = '/content/drive/MyDrive/Consu_douane/unsigned.pdf'
output_pdf = '/content/drive/MyDrive/Consu_douane/ocr_output.pdf'

ocrmypdf.ocr(
    input_pdf,
    output_pdf,
    force_ocr=True,
    output_type='pdf',
    deskew=True,
    clean=True,
    #remove_background=True,
    optimize=0,
    use_threads=True,
    jobs=4,
)

print(f"OCR’d PDF written to {output_pdf}")

""" 2) Now we will cut our opinions PDF to have the opinions of each stakeholder based on their affiliation (canton, umbrella organizations, individual).
 We will use the existing bookmarks in the document for this purpose.
"""

def flatten(outlines, level=0):
    flat = []
    for o in outlines:
        if isinstance(o, list):
            flat += flatten(o, level+1)
        else:
            # o.title, o.page_number (0-indexed)
            flat.append((o.title, level, reader.get_destination_page_number(o)))
    return flat

entries = flatten(outlines)
# entries = [(“Chapter 1”, 0, 0), (“1.1 Introduction”, 1, 2), …]
# 1) Output base
base_out = os.path.expanduser('/content/drive/MyDrive/Consu_douane/Extracted_Chapters')
os.makedirs(base_out, exist_ok=True)

# 2) Prepare list sorted by page
entries = sorted(entries, key=lambda x: x[2])

# 3) Iterate and cut
for idx, (title, level, start) in enumerate(entries):
    # Only process levels 1 and 2 (chapters and sub-chapters)
    if level not in (0,1): continue

    # Determine the end page: page of the next entry at the same or lower level
    end = None
    for next_title, next_level, next_page in entries[idx+1:]:
        if next_level <= level:
            end = next_page
            break
    if end is None:
        end = len(reader.pages)

    # Clean the name for the file system
    safe = re.sub(r'[\\/:"*?<>|]+', '_', title).strip()
    if level == 0:
        chap_dir = os.path.join(base_out, safe)
        os.makedirs(chap_dir, exist_ok=True)
    else:
        # level 1 → sub-chapter
        # Find the index of the last level 0 entry before the current index
        prev_level_0_indices = [i for i,(t,l,p) in enumerate(entries) if i<idx and l==0]
        if not prev_level_0_indices:
            # If there are no level 0 entries before this level 1 entry,
            # it means this is likely a section before the first main chapter.
            # We can put it directly under base_out or skip it depending on the desired behavior.
            # For this fix, we'll place it directly under base_out.
            chap_dir = os.path.join(base_out, safe)
        else:
            # Use the last level 0 entry's title for the parent directory
            parent_level_0_title = entries[prev_level_0_indices[-1]][0]
            chap_dir = os.path.join(base_out,
                                    re.sub(r'[\\/:"*?<>|]+', '_', parent_level_0_title),
                                    safe)

        os.makedirs(chap_dir, exist_ok=True)

    # Write the partial PDF
    writer = PdfWriter()
    for p in range(start, end):
        writer.add_page(reader.pages[p])

    out_path = os.path.join(chap_dir, f"{safe}.pdf")
    with open(out_path, 'wb') as f:
        writer.write(f)
    print(f"– Saved: {out_path} (pages {start+1}–{end})")

"""Maintenant que nous avons nos fichiers découpes nous allons pouvoirs commencer de faire nos analyses grace au NLP

Now that we have our cut files, we can start our analyses using NLP

 Before starting, we need to divide our files according to the language in which they are written.
 Indeed, the prompt that we will apply to them must be in the language of the document to guarantee optimal results.
"""

for pdf_path in src_root.rglob('*.pdf'):
    try:
        reader = PdfReader(str(pdf_path))
        # extract text from the first few pages to speed up
        sample = ""
        for p in reader.pages[:3]:
            text = p.extract_text() or ""
            sample += text + "\n"
        # detect language probabilities
        langs = detect_langs(sample)
        top = langs[0]  # e.g. “fr:0.99”
        lang_code = top.lang
    except (LangDetectException, Exception) as e:
        # skip files we can’t read or detect
        print(f"⚠️ Skipping {pdf_path.name}: {e}")
        continue

    # decide destination based on highest‐scoring language
    if lang_code == 'fr':
        dest_tree = fr_root
    elif lang_code == 'de':
        dest_tree = de_root
    elif lang_code == 'it':
        dest_tree = it_root
    else:
        # ignore anything that isn’t clearly French or German
        continue

    # 4) Reconstruct the same relative path under the chosen root
    rel = pdf_path.relative_to(src_root)
    target = dest_tree / rel
    target.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(pdf_path, target)
    print(f"→ {pdf_path.name}  →  {target}")

"""We can now begin our thematic analysis.
To do this, we will apply a prompt to each text and retrieve the responses in an Excel file.
 Then, we will take all these themes and apply a new analysis to arrive at major similar themes between actors and then indicate it in our Excel file.

 We will do this for each of the national languages present in the opinions, namely Italian, German, and French.
Once this is done, we will group our themes and translate them all into French.
"""

base_dir     = Path('/content/drive/MyDrive/Consu_douane')
roots = {
    "FR": base_dir / "Extracted_French",
    "DE": base_dir / "Extracted_German",
    "IT": base_dir / "Extracted_Italian",
}
output_excel = base_dir / "ollama_outputs_with_thematics.xlsx"

# 3) Templates per language (unchanged)
templates = {
    "FR": {
        "resume": (
            "Tu es un haut-fonctionnaire qui est mandaté pour produire un rapport de résultat "
            "sur un processus de consultation sur"
            " une réforme  de la franchise d’impôt à l’importation de biens en petites quantités. "
            "Veuillez produire un résumé clair et synthétique du document ci-dessous, "
            "en restituant fidèlement les idées principales et la progression argumentative :\n\n"
            "{texte}\n\n"
            "**Réponds** sans en-tête, sans guillemets, sans autre texte."
        ),
        "themes": (
            "Tu es un chercheur en sciences sociales, spécialiste en analyse thématique QUALITATIVE. "
            "À partir du texte fourni ci-dessous, réalise une **analyse thématique interprétative** "
            "en identifiant les **thématiques latentes** (valeurs, préoccupations, représentations) "
            "exprimées par l’acteur dans la procédure de consultation sur la réforme"
            " de la franchise d’impôt à l’importation de biens en petites quantités \n\n"
            "Consignes strictes :\n"
            "- Donne uniquement une liste à puces.\n"
            "- Formule chaque thématique de façon concise (2 à 4 mots), au niveau interprétatif "
            "(valeurs/principes), et non contextuel.\n"
            "- Classe-les par ordre décroissant d’importance (poids discursif).\n"
            "- Ne donne ni titre, ni guillemets, ni texte explicatif.\n"
            "Texte à analyser :\n"
            "{texte}\n\n"
            "Thématiques latentes :"
        ),
    },
   "DE": {
        "resume": (
            "Du bist ein hoher Beamter, der beauftragt wurde, einen Ergebnisbericht über ein Konsultationsverfahren "
            "zur Reform der Steuerfreigrenze für die Einfuhr von Kleinsendungen zu erstellen. "
            "Bitte erstelle eine klare und prägnante Zusammenfassung des folgenden Dokuments, "
            "die die Hauptgedanken und den Argumentationsverlauf originalgetreu wiedergibt:\n\n"
            "{texte}\n\n"
            "**Antworte** ohne Überschrift, ohne Anführungszeichen, ohne weiteren Text."
        ),
        "themes": (
            "Du bist ein Sozialwissenschaftler mit Spezialisierung auf QUALITATIVE thematische Analyse. "
            "Führe aus dem untenstehenden Text eine interpretative thematische Analyse durch, indem du "
            "die latenten Themen (Werte, Anliegen, Repräsentationen) identifizierst, die der Akteur im "
            "Konsultationsverfahren zur Reform der Steuerfreigrenze für die Einfuhr von Kleinsendungen äußert.\n\n"
            "Strikte Anweisungen:\n"
            "- Gib ausschließlich eine Aufzählungsliste aus.\n"
            "- Formuliere jedes Thema prägnant (2–4 Wörter) auf interpretativer Ebene (Werte/Prinzipien), nicht kontextuell.\n"
            "- Ordne sie nach absteigendem Gewicht (diskursives Gewicht).\n"
            "- Nutze weder Titel noch Anführungszeichen noch erklärenden Text.\n\n"
            "Zu analysierender Text:\n"
            "{texte}\n\n"
            "Latente Themen:"
        ),
    },
    "IT": {
        "resume": (
            "Sei un alto funzionario incaricato di redigere un rapporto sui risultati di una consultazione "
            "sulla riforma della franchigia fiscale per le importazioni di piccole quantità. "
            "Genera un riassunto chiaro e sintetico del documento seguente, "
            "restituendo fedelmente le idee principali e il percorso argomentativo:\n\n"
            "{texte}\n\n"
            "**Rispondi** senza intestazione, senza virgolette, senza altro testo."
        ),
        "themes": (
            "Sei un ricercatore in scienze sociali, specialista in analisi tematica QUALITATIVA. "
            "A partire dal testo fornito di seguito, esegui un'analisi tematica interpretativa identificando "
            "i temi latenti (valori, preoccupazioni, rappresentazioni) espressi dall’attore nella procedura "
            "di consultazione sulla riforma della franchigia fiscale per le importazioni di piccole quantità.\n\n"
            "Istruzioni rigorose:\n"
            "- Fornisci esclusivamente un elenco puntato.\n"
            "- Formula ogni tema in modo conciso (2–4 parole) a livello interpretativo (valori/principi), non contestuale.\n"
            "- Ordinali in ordine decrescente di importanza (peso discorsivo).\n"
            "- Non includere titoli, virgolette o testi esplicativi.\n\n"
            "Testo da analizzare:\n"
            "{texte}\n\n"
            "Temi latenti:"
        ),
    },
}

results = []
for lang, folder in roots.items():
    if not folder.exists():
        print(f"⚠️ Folder not found for {lang}: {folder}")
        continue
    tpl = templates[lang]
    for pdf_path in folder.rglob("*.pdf"):
        # extraction and snippet
        reader    = PdfReader(str(pdf_path))
        full_text = "\n".join(page.extract_text() or "" for page in reader.pages)

        # --- Step 1: summary ---
        prompt_sum = tpl["resume"].format(texte=full_text)
        print("\n=== SUMMARY PROMPT ===\n", prompt_sum)

        proc_sum = subprocess.run(
            ["ollama", "run", model_name],
            input=prompt_sum, text=True, capture_output=True
        )
        print("=== SUMMARY STDOUT ===\n", proc_sum.stdout)

        if proc_sum.returncode != 0:
            print(f"⚠️ Summary failed ({lang}) for {pdf_path.name}")
            summary = ""
        else:
            summary = proc_sum.stdout.strip()

        # --- Step 2: thematics ---
        prompt_them = tpl["themes"].format(texte=full_text)
        print("\n=== THEMATICS PROMPT ===\n", prompt_them)

        proc_them = subprocess.run(
            ["ollama", "run", model_name],
            input=prompt_them, text=True, capture_output=True
        )
        print("=== THEMATICS STDOUT ===\n", proc_them.stdout)

        if proc_them.returncode != 0:
            print(f"⚠️ Thematics failed ({lang}) for {pdf_path.name}")
            thematics = ""
        else:
            thematics = proc_them.stdout.strip()

        results.append({
            "lang":      lang,
            "filename":  pdf_path.name,
            "summary":   summary,
            "thematics": thematics
        })

# 6) Save
df = pd.DataFrame(results)
df.to_excel(output_excel, index=False)
print("✅ Results saved to:", output_excel)
print(df.head())

"""Now we will translate the themes of the different opinions so that we can process them together later."""

# 1) Paths
base_dir     = Path('/content/drive/MyDrive/Consu_douane')
input_excel  = base_dir / "ollama_outputs_with_thematics.xlsx"
output_excel = base_dir / "ollama_outputs_with_thematics.xlsx"

# 2) Load the Excel
df = pd.read_excel(input_excel)
print("➡️ Available columns:", df.columns.tolist())

# 3) Translation template
translate_template = (
    "Veuillez traduire en français la liste de thèmes suivante, "
    "en conservant la structure en liste à puces si présente, "
    "et en veillant à ce que le contenu soit clair et précis :\n\n"
    "{thematics}\n\n"
    "**Réponds** sans en-tête, sans guillemets, sans autre texte."
    "Thèmes en français :"
)

# 4) Translation function
def translate_thematics(text):
    if not text.strip():
        return ""  # nothing to translate
    prompt = translate_template.format(thematics=text)
    # Display the prompt
    print("\n=== PROMPT SENT ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt, text=True, capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Failure for «{text[:30]}…»\n", proc.stderr.strip())
        return ""
    response = proc.stdout.strip()
    print("=== MODEL RESPONSE ===")
    print(response)

    return proc.stdout.strip()

# 5) Apply the translation
df['thematics_fr'] = df['thematics'].astype(str).apply(translate_thematics)

# 6) Save
df.to_excel(output_excel, index=False)
print("✅ Translated columns added and file saved to:", output_excel)

# 1) Paths & parameters
base_dir    = Path('/content/drive/MyDrive/Consu_douane')
input_file  = base_dir / "ollama_outputs_with_thematics.xlsx"
col_name    = "thematics_fr"

# 2) Load the DataFrame
df = pd.read_excel(input_file)

# 3) Build and display the prompt
texts    = df[col_name].dropna().astype(str).tolist()
numbered = "\n".join(f"{i+1}. {t}" for i,t in enumerate(texts,1))
prompt   = f"""\
Tu es un chercheur en sciences sociales, spécialiste en analyse thématique qualitative.
Voici la liste complète des thématique extraits de la colonne « {col_name} » :
{numbered}

Effectue un regroupement en exactement 5 catégories thématiques représentatives et distinguables.
**Réponds** sans en-tête, sans guillemets, sous la forme :
<catégorie> : description de la catégorie
"""
print("=== PROMPT SENT ===\n", prompt)

# 4) Call Ollama
proc     = subprocess.run(
    ["ollama","run",model_name],
    input=prompt,
    text=True,
    capture_output=True
)
if proc.returncode != 0:
    raise RuntimeError(f"Ollama error:\n{proc.stderr}")
response = proc.stdout.strip()
print("=== MODEL RESPONSE ===\n", response)

# 5) Delete the old column if it exists
if 'general_theme_codebook' in df.columns:
    df = df.drop(columns=['general_theme_codebook'])

# 6) Insert the new column just after 'thematics_fr'
insert_at = df.columns.get_loc(col_name) + 1
df.insert(insert_at, 'general_theme_codebook', "")

# 7) Place the model's response in the first cell below the header
df.iat[0, insert_at] = response

# 8) Save
df.to_excel(input_file, index=False)
print("✅ Column 'general_theme_codebook' added, response inserted in row 1.")

"""We separate the themes from their descriptions into a new column

"""

ddef extract_themes(cell):
    # Convert to string and split on all types of line breaks
    lines = re.split(r'[\r\n]+', str(cell))
    themes = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if ':' in line:
            theme, _ = line.split(':', 1)
            themes.append(theme.strip())
        else:
            # Case where there is no ":"
            themes.append(line)
    return themes

# 3) Apply and create a list column
df['general_theme_fr'] = df['general_theme_codebook'].apply(extract_themes)
df["general_theme_fr"] = df["general_theme_fr"].apply(lambda lst: "\n".join(lst))

# 4) Save back to Excel
df.to_excel(input_file, index=False)

"""To avoid any hallucination problem of our model, we add the neutral category in our cell of general themes."""

ancienne_valeur = df.at[0, "general_theme_codebook"]
if pd.isna(ancienne_valeur):
    ancienne_valeur = ""


df.at[0, "general_theme_fr"] = f"{ancienne_valeur} \\nAucun de ces thèmes: le document ne correspond a aucun des autres thèmes mentionnés"
df.to_excel(input_file, index=False)

"""To translate the general themes into German and Italian so that they can be applied to the texts later."""

col_name = "general_theme_fr"

df = pd.read_excel(input_excel)

translate_template = (
    "Bitte übersetzen Sie die folgende Themenliste ins Deutsche, "
    "unter Beibehaltung der Aufzählungsstruktur, falls vorhanden, "
    "und achten Sie darauf, dass der Inhalt klar und präzise ist:\n\n"
    "{thematics}\n\n"
    "**beantworte** ohne Überschrift, ohne Anführungszeichen, ohne weiteren Text. "
    "Themen auf Deutsch:"
)


def translate_thematics(general_theme_fr):
    if not general_theme_fr.strip():
        return ""
    prompt = translate_template.format(thematics=general_theme_fr)
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt,
        text=True,
        capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Échec pour «{theme_fr[:30]}…» : {proc.stderr.strip()}")
        return ""
    response = proc.stdout.strip()

    print("=== RÉPONSE DU MODÈLE ===")
    print(response)
    return response


translated = df[col_name].fillna("").astype(str).apply(translate_thematics)


if 'general_theme_de' in df.columns:
    df = df.drop(columns=['general_theme_de'])
insert_at = df.columns.get_loc(col_name) + 1

df.insert(insert_at, 'general_theme_de', translated)

df.to_excel(output_excel, index=False)
print(f"✅ Colonne 'general_theme_de' ajoutée, réponses enregistrées dans {output_excel}")

col_name = "general_theme_fr"


translate_template = (
    "Traduci il seguente elenco di temi in italiano, "
    "mantenendo la struttura dell'elenco puntato, se presente, "
    "e assicurandoti che il contenuto sia chiaro e preciso:\n\n"
    "{thematics}\n\n"
    "**rispondi** senza titoli, senza virgolette, senza altro testo aggiuntivo. "
    "Temi in italiano:"
)


def translate_thematics(general_theme_fr):
    if not general_theme_fr.strip():
        return ""
    prompt = translate_template.format(thematics=general_theme_fr)
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt,
        text=True,
        capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Échec pour «{theme_fr[:30]}…» : {proc.stderr.strip()}")
        return ""
    response = proc.stdout.strip()
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)
    return response

translated = df[col_name].fillna("").astype(str).apply(translate_thematics)

if 'general_theme_it' in df.columns:
    df = df.drop(columns=['general_theme_it'])
insert_at = df.columns.get_loc(col_name) + 1
df.insert(insert_at, 'general_theme_it', translated)

df.to_excel(output_excel, index=False)
print(f"✅ Colonne 'general_theme_it' ajoutée, réponses enregistrées dans {output_excel}")

base_dir = Path('/content/drive/MyDrive/Consu_douane')
input_excel = base_dir / "ollama_outputs_with_thematics.xlsx"
output_excel = input_excel
roots = {
    "FR": base_dir / "Extracted_French",
    "DE": base_dir / "Extracted_German",
    "IT": base_dir / "Extracted_Italian",
}

df = pd.read_excel(input_excel)
general_themes = {}
for lang in ["FR", "DE", "IT"]:
    col = f"general_theme_{lang.lower()}"
    if col not in df.columns:
        raise KeyError(f"Colonne manquante dans Excel: {col}")
    themes = df[col].dropna().unique().tolist()
    general_themes[lang] = ", ".join(themes)

prompt_template = {
    "FR": (
        "Tu es un chercheur en sciences sociales, spécialiste en analyse thématique qualitative.\n"
        "Pour chaque document, indique **uniquement** le thème général correspondant.\n\n"
        "Texte à analyser:\n{texte}\n\n"
        "Thèmes généraux possibles : {general}\n\n"
        "Réponds **exactement** par la seule catégorie choisie (pas de CSV, pas de JSON)."
    ),
    "DE": (
        "Du bist ein Sozialwissenschaftler mit Spezialisierung auf qualitative thematische Analyse.\n"
        "Gib für jedes Dokument **ausschließlich** das zutreffende allgemeine Thema an.\n\n"
        "Zu analysierender Text:\n{texte}\n\n"
        "Mögliche allgemeine Themen : {general}\n\n"
        "Antworte **exakt** mit der ausgewählten Kategorie (kein CSV, kein JSON)."
    ),
    "IT": (
        "Sei un ricercatore in scienze sociali, specialista nell'analisi tematica qualitativa.\n"
        "Per ogni documento, indica **esclusivamente** il tema generale corrispondente.\n\n"
        "Testo da analizzare:\n{texte}\n\n"
        "Possibili temi generali  : {general}\n\n"
        "Rispondi **esattamente** indicando solo la categoria scelta (no CSV, no JSON)."
    )
}

def categorize_document(full_text: str, template: str, general_list: str) -> str:
    prompt = template.format(texte=full_text, general=general_list)
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt,
        text=True,
        capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Erreur : {proc.stderr.strip()}")
        return ""
    response = proc.stdout.strip()
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)
    return response.splitlines()[0] if response else ""

categories = []
files = []
langs = []
for lang, folder in roots.items():
    if not folder.exists():
        continue
    template = prompt_template[lang]
    general_list = general_themes[lang]
    for pdf_path in folder.rglob("*.pdf"):
        reader = PdfReader(str(pdf_path))
        full_text = "\n".join(page.extract_text() or "" for page in reader.pages)
        category = categorize_document(full_text, template, general_list)
        files.append(pdf_path.name)
        langs.append(lang)
        categories.append(category)
df['general_category'] = pd.Series(categories, index=df.index[:len(categories)])

df.to_excel(output_excel, index=False)
print(f"✅ Colonnes ajoutées et mis à jour dans : {output_excel}")

df = pd.read_excel(input_excel)
print("➡️ Colonnes disponibles :", df.columns.tolist())

translate_template = (
    "Veuillez traduire en français le thème suivant"
    ":\n\n"
    "{category}\n\n"
    "**Réponds** sans en-tête, sans guillemets, sans autre texte. "
    "Thème en français :"
)

def translate_category(category: str) -> str:
    if not category.strip():
        return ""
    prompt = translate_template.format(category=category)
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt,
        text=True,
        capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Échec pour «{category[:30]}…» : {proc.stderr.strip()}")
        return ""
    response = proc.stdout.strip()
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)
    return response

df['category_fr'] = df['general_category'].fillna("").astype(str).apply(translate_category)

df.to_excel(output_excel, index=False)
print(f"✅ Traductions enregistrées dans : {output_excel}")

""" In case we use an agentic model (like Qwen3), it is necessary to remove all the reasoning phase of the model present in these responses.

 We separate the themes from their descriptions into a new column
"""

def extract_themes(cell):
    lines = re.split(r'[\r\n]+', str(cell))
    themes = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if ':' in line:
            theme, _ = line.split(':', 1)
            themes.append(theme.strip())
        else:
            themes.append(line)
    return themes

df['general_theme_fr'] = df['general_theme_codebook'].apply(extract_themes)
df["general_theme_fr"] = df["general_theme_fr"].apply(lambda lst: "\n".join(lst))

df.to_excel(input_file, index=False)

theme_col = 'category_fr'

df = df.dropna(subset=[theme_col])
themes = df[theme_col].tolist()

# Compute embeddings using a pretrained model
# Choice of embedding model: "all-MiniLM-L6-v2"
model = SentenceTransformer('all-MiniLM-L6-v2')
theme_embeddings = model.encode(themes)

# Calculate pairwise cosine similarity
similarity_matrix = cosine_similarity(theme_embeddings)

# Set diagonal to 0 to ignore self-similarity
np.fill_diagonal(similarity_matrix, 0)

# Merge themes based on similarity threshold
similarity_threshold_low = 0.80
similarity_threshold_high = 0.999

# Create a mapping for merged themes
theme_map = dict()

for idx, theme in enumerate(themes):
    if theme in theme_map:
        continue

    # Find indices where similarity is within threshold
    similar_idxs = np.where(
        (similarity_matrix[idx] >= similarity_threshold_low) &
        (similarity_matrix[idx] <= similarity_threshold_high)
    )[0]

    # Merge themes into the most frequent canonical theme
    candidates = [themes[i] for i in similar_idxs] + [theme]
    canonical = df[df[theme_col].isin(candidates)][theme_col].value_counts().idxmax()

    for candidate in candidates:
        theme_map[candidate] = canonical

# Apply merging
df['cleaned_theme'] = df[theme_col].map(theme_map)

# Recount theme frequencies after cleaning
cleaned_counts = df['cleaned_theme'].value_counts()

# --- Graph Styling (Themes Only) ---
fig, ax = plt.subplots(figsize=(10, 10))
explode = [0.05] * len(cleaned_counts)

wedges, texts, autotexts = ax.pie(
    cleaned_counts,
    autopct='%1.1f%%',
    startangle=140,
    explode=explode,
    pctdistance=0.75,
    wedgeprops={'linewidth': 1, 'edgecolor': 'white'}
)

ax.set(aspect="equal")
ax.set_title(
    f"Distribution of thematics\n Number of responses : {cleaned_counts.sum()}",
    fontsize=16,
    pad=30
)

legend_labels = ["\n".join(textwrap.wrap(cat, width=15)) for cat in cleaned_counts.index]

legend = ax.legend(
    wedges,
    legend_labels,
    title="Thematics",
    loc="center left",
    bbox_to_anchor=(1.02, 0.5),
    fontsize=9,
    title_fontsize=12,
    ncol=3,
    frameon=True,
    shadow=True,
    facecolor='white',
    framealpha=0.8,
    edgecolor='gray',
    borderpad=1,
    handlelength=1.2,
    handletextpad=0.5,
    columnspacing=2.5,
    labelspacing=1.2
)
legend.get_frame().set_boxstyle('round,pad=0.5')

plt.tight_layout()
plt.show()

# --- Second Graph (Themes with Actors) ---
actors_by_cat = df.groupby('cleaned_theme')['filename'].apply(list)

fig, ax = plt.subplots(figsize=(10, 10))

wedges, texts, autotexts = ax.pie(
    cleaned_counts,
    autopct='%1.1f%%',
    startangle=140,
    explode=explode,
    pctdistance=0.75,
    wedgeprops={'linewidth': 1, 'edgecolor': 'white'}
)

ax.set(aspect="equal")
ax.set_title(
    f"Distribution of thematics\n Number of responses : {cleaned_counts.sum()}",
    fontsize=16,
    pad=30
)

def wrap_label(cat):
    cat_wrapped = "\n".join(textwrap.wrap(cat, width=15))
    acteurs = actors_by_cat.get(cat, [])
    details_wrapped = "\n".join(textwrap.wrap(", ".join(acteurs), width=20))
    label = rf"{{{cat_wrapped}}} : {len(acteurs)}"
    if acteurs:
        label += "\n" + details_wrapped
    return label

legend_labels = [wrap_label(cat) for cat in cleaned_counts.index]

legend = ax.legend(
    wedges,
    legend_labels,
    title="Thematics and actors",
    loc="center left",
    bbox_to_anchor=(1.02, 0.5),
    fontsize=9,
    title_fontsize=12,
    ncol=3,
    frameon=True,
    shadow=True,
    facecolor='white',
    framealpha=0.8,
    edgecolor='gray',
    borderpad=1,
    handlelength=1.2,
    handletextpad=0.5,
    columnspacing=2.5,
    labelspacing=1.2
)
legend.get_frame().set_boxstyle('round,pad=0.5')

plt.tight_layout()
plt.show()

# Save the figure
output_dir = './graphs'
os.makedirs(output_dir, exist_ok=True)
output_path = os.path.join(output_dir, "distribution_cleaned_themes_actors.pdf")
fig.savefig(output_path, bbox_inches="tight")
plt.close()

print(f"✅ Graphique enregistré dans : {output_path}")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


output_excel = base_dir / "ollama_outputs_with_thematics.xlsx"

file_map = {}
for lang, folder in roots.items():
    if not folder.exists():
        logger.warning(f"Dossier non trouvé: {folder}")
        file_map[lang] = {}
    else:
        lang_map = {}
        for p in folder.rglob("*.pdf"):
            name_norm = unicodedata.normalize("NFC", p.name)
            lang_map[name_norm] = p
        file_map[lang] = lang_map
        logger.info(f"{lang}: {len(lang_map)} fichiers PDF indexés")

if output_excel.exists():
    df = pd.read_excel(output_excel, engine="openpyxl")
    df.columns = df.columns.str.strip().str.lower()
    for col in ["lang", "filename", "volet1", "avis"]:
        if col not in df.columns:
            df[col] = None
    df.rename(columns={"avis": "Avis"}, inplace=True)
else:
    records = []
    for lang, files in file_map.items():
        for fname in files:
            records.append({"lang": lang, "filename": fname, "volet1": None, "Avis": None})
    df = pd.DataFrame(records)
    logger.info(f"DataFrame initialisé avec {len(df)} lignes")

templates_simple = {
    "FR": (
        "Tu es un haut-fonctionnaire chargé de produire un rapport de consultation sur une réforme de la franchise d’impôt à l’importation de biens en petites quantités en Suisse.\n"
        "Pour chaque avis d'acteur sur cet objet , indiquez si l'avis est positif, négatif ou neutre.\n"
        "Répond **UNIQUEMENT** par un seul mot parmi : « positif », « neutre » ou « négatif ».\n\n"
        "Objet :\n"
        "Un abaissement général de la franchise-valeur a 150 francs par personne pour les marchandises du trafic touristique.\n\n"
        "Avis à analyser :\n{texte}"
    ),
    "DE": (
        "Du bist ein hoher Beamter, der beauftragt wurde, einen Konsultationsbericht über die Reform der Steuerfreigrenze für die Einfuhr von Kleinsendungen in der Schweiz zu erstellen.\n"
        "Für jede Stellungnahme eines Akteurs zu diesem Gegenstand gib an, ob die Stellungnahme positiv, negativ oder neutral ist.\n"
        "Antworte **AUSSCHLIESSLICH** mit einem einzigen Wort: „positiv“, „neutral“ oder „negativ“.\n\n"
        "Gegenstand:\n"
        "Eine generelle Senkung der Freigrenze auf 150 Franken pro Person für Touristenverkehrswaren.\n\n"
        "Stellungnahme zur Analyse:\n"
        "{texte}"
    ),
    "IT": (
        "Sei un alto funzionario incaricato di redigere un rapporto di consultazione sulla riforma della franchigia fiscale per le importazioni di piccole quantità in Svizzera.\n"
        "Per ciascun parere di un attore su questo oggetto, indica se il parere è positivo, negativo o neutro.\n"
        "Rispondi **ESCLUSIVAMENTE** con una sola parola tra: “positivo”, “neutro” o “negativo”.\n\n"
        "Oggetto:\n"
        "Una riduzione generale della franchigia valore a 150 franchi per persona per le merci del traffico turistico.\n\n"
        "Parere da analizzare:\n"
        "{texte}"
    ),
}
allowed_map = {
    "FR": {"positif", "neutre", "négatif"},
    "DE": {"positiv", "neutral", "negativ"},
    "IT": {"positivo", "neutro", "negativo"},
}
MAX_RETRIES = 3
SAVE_INTERVAL = 1


def extract_text(pdf_path: Path) -> str:
    reader = PdfReader(str(pdf_path))
    return "\n".join(page.extract_text() or "" for page in reader.pages)

for idx, row in df.iterrows():
    if pd.notna(row.get("volet1")):
        continue

    lang = row["lang"]
    fname = unicodedata.normalize("NFC", str(row["filename"]).strip())
    pdf_path = file_map.get(lang, {}).get(fname)
    if not pdf_path:
        logger.error(f"Fichier introuvable : {lang}/{fname}")
        continue

    logger.info(f"Traitement de {lang}/{fname} (index {idx})")
    full_text = extract_text(pdf_path)
    prompt = templates_simple[lang].format(texte=full_text)

    for attempt in range(1, MAX_RETRIES + 1):
        proc = subprocess.run(
            ["ollama", "run", model_name],
            input=prompt,
            text=True,
            capture_output=True
        )
        resp = proc.stdout.strip().lower()
        print("\n=== PROMPT ENVOYÉ ===")
        print(prompt)
        print("=== RÉPONSE DU MODÈLE ===")
        print(resp)

        if resp in allowed_map[lang]:
            df.at[idx, "volet1"] = resp
            df.at[idx, "Avis"] = resp
            logger.info(f"Réponse valide au tour {attempt} : {resp}")
            break
        else:
            logger.warning(f"Tentative {attempt} invalide : «{resp}»")
            df.at[idx, "volet1"] = None
            df.at[idx, "Avis"] = None
    else:
        logger.error(f"Échec après {MAX_RETRIES} essais pour l’index {idx}")

    if idx % SAVE_INTERVAL == 0 and idx > 0:
        try:
            df.to_excel(output_excel, index=False, engine="openpyxl")
            logger.info(f"Sauvegarde intermédiaire à l’index {idx}")
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde intermédiaire : {e}")

try:
    df.to_excel(output_excel, index=False, engine="openpyxl")
    logger.info(f"Fichier sauvegardé : {output_excel}")
except Exception as e:
    logger.error(f"Erreur lors de l'écriture du fichier final : {e}")

print("✅ Traitement terminé.")

translation_map = {
    "positiv":  "positif",
    "negativ":  "négatif",
    "neutral":  "neutre",
    "positiva": "positif",
    "negativo": "négatif",
    "neutrale": "neutre",
    "positif":  "positif",
    "negatif":  "négatif",
    "neutre":   "neutre"
}


df['volet1_norm'] = df['volet1'].str.strip().str.lower()

df['volet1_fr'] = df['volet1_norm'].map(translation_map).fillna(df['volet1'])

df.drop(columns=['volet1_norm'], inplace=True)

print(df[['filename','volet1','volet1_fr']].head())

df.to_excel(input_excel, index=False)

output_dir = '/content/drive/MyDrive/Consu_douane/Graph'
os.makedirs(output_dir, exist_ok=True)

for volet in ['volet1_fr']:
    counts = df[volet].value_counts()
    actors_by_cat = df.groupby(volet)['filename'].apply(list)
    total = counts.sum()

    fig, ax = plt.subplots(figsize=(12, 8))

    color_map = {'négatif': 'red', 'positif': 'green', 'neutre': 'lightblue'}
    colors = [color_map.get(c, 'gray') for c in counts.index]
    explode = [0.05] * len(counts)

    wedges, texts, autotexts = ax.pie(
        counts,
        labels=None,
        autopct=lambda pct: f"{pct:.1f}%",
        pctdistance=0.6,
        startangle=140,
        explode=explode,
        wedgeprops={'linewidth': 1, 'edgecolor': 'white'},
        colors=colors
    )
    ax.set(aspect="equal")
    ax.set_title(f"Number of response {total}", fontsize=18, pad=20)

    legend_labels = []
    for cat in counts.index:
        n = counts[cat]
        detail = ", ".join(actors_by_cat[cat])
        wrapped = textwrap.fill(detail, width=30)
        legend_labels.append(f"{cat} ({n})\n{wrapped}")
    ax.legend(
        wedges,
        legend_labels,
        title="Opinion des acteurs",
        loc="center left",
        bbox_to_anchor=(1.02, 0.5),
        fontsize=9,
        title_fontsize=12,
        frameon=True,
        shadow=True,
        facecolor='white',
        framealpha=0.8,
        edgecolor='gray',
        handlelength=1.5,
        borderpad=0.8
    )

    plt.tight_layout()
    plt.show()
    output_path = os.path.join(output_dir, f"repartition_{volet}.pdf")
    fig.savefig(output_path, bbox_inches='tight')
    plt.close()

print(f"✅ Graphiques enregistrés dans : {output_dir}")

"""We are now trying to develop a prompt that will allow you to see the proposed modifications made by the various stakeholders."""

import logging

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

templates = {
    "FR": {
        "Amendement": (
            "Tu es un haut-fonctionnaire mandaté pour produire un rapport sur la réforme "
            "de la franchise d’impôt à l’importation de biens en petites quantités en Suisse.\n"
            "Tu recevras **un avis de partie prenante à la fois**. Pour chaque avis, fais :\n"
            "1. **Extrais uniquement les propositions de modification** sous forme de liste à puces.\n"
            "2. Pour chaque proposition : reformulation concise, catégorie, référence précise.\n"
            "3. **Pas d'autre commentaire**.\n\n"
            "**Texte :** {texte}"
        )
    },
    "DE": {
        "Amendement": (
            """\
Du bist ein hoher Beamter, beauftragt, einen Bericht über die Reform der Steuerfreigrenze für die Einfuhr von Kleinsendungen in der Schweiz zu erstellen.
Du wirst **jeweils nur eine Stellungnahme von Stakeholdern** erhalten. Für jede Stellungnahme:

1. **Extrahiere ausschließlich die Änderungsvorschläge** und gib sie als Aufzählungsliste aus.
2. Für jeden Vorschlag:
   - prägnante Umformulierung
   - Kategorie
   - genaue Referenz
3. **Keinen weiteren Kommentar**.

**Text:** {texte}"""
        )
    },
    "IT": {
        "Amendement": (
            """\
Sei un alto funzionario incaricato di redigere un rapporto sulla riforma della franchigia fiscale per le importazioni di piccole quantità in Svizzera.
Riceverai **un parere di stakeholder alla volta**. Per ciascun parere:

1. **Estrai esclusivamente le proposte di modifica** e riportale come elenco puntato.
2. Per ogni proposta:
   - riformulazione concisa
   - categoria
   - riferimento preciso
3. **Nessun altro commento**.

**Testo:** {texte}"""
        )
    },
}


if output_excel.exists():
    try:
        df_existing = pd.read_excel(output_excel)
        logger.info("Loaded existing results from %s", output_excel)
    except Exception as e:
        logger.error("Failed to read existing Excel: %s", e)
        df_existing = pd.DataFrame(columns=["filename", "Amendement"])
else:
    df_existing = pd.DataFrame(columns=["filename", "Amendement"])

def extract_text_from_pdf(path: Path) -> str:
    """Lit et concatène le texte de chaque page du PDF."""
    try:
        reader = PdfReader(str(path))
        texts = [page.extract_text() or "" for page in reader.pages]
        full = "\n".join(texts)
        return full
    except Exception as e:
        logger.warning("Erreur lors de l'extraction de texte pour %s: %s", path, e)
        return ""

print("\n=== PROMPT ENVOYÉ ===")
print(prompt)
def call_llm(prompt: str) -> str:
    """Appel subprocess à l'LLM et retourne la sortie."""
    try:
        proc = subprocess.run(
            ["ollama", "run", model_name],
            input=prompt,
            text=True,
            capture_output=True,
            check=True,
        )
        return proc.stdout.strip()
    except subprocess.CalledProcessError as e:
        logger.error("LLM call failed: %s", e.stderr)
        return ""
        response = proc.stdout.strip()
        print("=== RÉPONSE DU MODÈLE ===")
        print(response)


amend_dict = {}
for lang, folder in roots.items():
    if lang not in templates:
        logger.warning("No template for language %s, skipping", lang)
        continue
    tpl = templates[lang]["Amendement"]
    for pdf_path in folder.rglob("*.pdf"):
        logger.info("Processing %s", pdf_path.name)
        text = extract_text_from_pdf(pdf_path)
        if not text.strip():
            logger.warning("No text extracted for %s, skipping LLM", pdf_path.name)
            amend_dict[pdf_path.name] = ""
            continue
        prompt = tpl.format(texte=full_text)
        result = call_llm(prompt)
        amend_dict[pdf_path.name] = result

if not df_existing.empty:
    df_existing.set_index("filename", inplace=True)
    df_existing["Amendement"] = pd.Series(amend_dict)
    df_final = df_existing.reset_index()
else:
    df_final = pd.DataFrame(
        [{"filename": fname, "Amendement": a} for fname, a in amend_dict.items()]
    )

try:
    df_final.to_excel(output_excel, index=False)
    logger.info("Results saved to %s", output_excel)
except Exception as e:
    logger.error("Failed to write Excel: %s", e)

print(df_final.head())

"""To finalize our analysis, we will ask our model for a general opinion on the whole consultation process, using the summaries produced."""

translate_template = (
    "Veuillez traduire en français ce court texte en veillant à ce que le contenu soit clair et précis :\n\n"
    "{summary}\n\n"
    "**Réponds** sans en-tête, sans guillemets, sans autre texte."
    "texte en français :"
)


def translate_thematics(text):
    if not text.strip():
        return ""
    prompt = translate_template.format(summary=text)
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt, text=True, capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Échec pour «{text[:30]}…»\n", proc.stderr.strip())
        return ""
    response = proc.stdout.strip()
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)

    return proc.stdout.strip()

df['summary_fr'] = df['summary'].astype(str).apply(translate_thematics)

df.to_excel(output_excel, index=False)
print("✅ Colonnes traduites ajoutées et fichier enregistré dans :", output_excel)

df.columns = df.columns.str.strip()

col_name = 'summary_fr'
if col_name not in df.columns:
    raise KeyError(f"La colonne '{col_name}' n’existe pas.")

texts = (
    df[col_name]
    .dropna()
    .astype(str)
    .str.strip()
    .loc[lambda s: s != ""]
    .tolist()
)
if not texts:
    raise ValueError(f"Aucun résumé trouvé dans '{col_name}'")

numbered = "\n".join(f"{i+1}. {t}" for i, t in enumerate(texts, 1))

# --- Construction du prompt
prompt = f"""\
Tu es un haut fonctionnaire chargé de produire un rapport synthétique sur une consultation concernant une réforme de la franchise d’impôt à l’importation de biens en petites quantités en Suisse.

Tu vas recevoir ci-dessous une liste numérotée contenant les résumés individuels des avis exprimés par chacune des parties prenantes concernant le sujet de consultation suivant :
« {col_name} »

{numbered}

Sur la base de ces résumés individuels, ta tâche consiste à produire une synthèse très succincte de l'opinion générale des parties prenantes sur le sujet, en suivant ces consignes strictes :

    1) Identifie une unique catégorie exprimant la tendance générale dominante parmi les avis (ex. consensus positif, consensus négatif, division, réserve générale, soutien conditionnel, etc.).
    2) Rédige une description concise explicitant clairement et précisément cette position générale, en mettant en évidence les points majeurs d'accord ou de désaccord mentionnés fréquemment par les parties prenantes.

Réponds sans en-tête, sans guillemets.
"""
print("=== PROMPT ENVOYÉ ===\n", prompt)

proc = subprocess.run(
    ["ollama", "run", model_name],
    input=prompt,
    text=True,
    capture_output=True
)
if proc.returncode != 0:
    raise RuntimeError(f"Ollama erreur :\n{proc.stderr}")

response = proc.stdout.strip()
print("=== RÉPONSE DU MODÈLE ===\n", response)


if 'Global_Summary' in df.columns:
    df = df.drop(columns=['Global_Summary'])

insert_at = df.columns.get_loc(col_name) + 1
df.insert(insert_at, 'Global_Summary', "")
df.iat[0, insert_at] = response

df.to_excel(input_excel, index=False)
print("✅ Colonne 'Global_Summary' ajoutée, réponse insérée en ligne 1.")

col_name = 'summary_fr'
if col_name not in df.columns:
    raise KeyError(f"La colonne '{col_name}' n’existe pas.")

texts = (
    df[col_name]
    .dropna()
    .astype(str)
    .str.strip()
    .loc[lambda s: s != ""]
    .tolist()
)
if not texts:
    raise ValueError(f"Aucun résumé trouvé dans '{col_name}'")

numbered = "\n".join(f"{i+1}. {t}" for i, t in enumerate(texts, 1))

prompt = f"""\
Tu es un haut fonctionnaire chargé de produire un rapport synthétique sur une consultation concernant une réforme de la franchise d’impôt à l’importation de biens en petites quantités en Suisse.

Tu vas recevoir ci-dessous une liste numérotée contenant les résumés individuels des avis exprimés par chacune des parties prenantes concernant le sujet de consultation suivant :
« {col_name} »

{numbered}

Sur la base de ces résumés individuels, ta tâche consiste à produire une synthèse des justifications principales des parties prenantes sur le sujet, il faut que tu donnes les grandes raisons pourquoi les acteurs sont contre ou pour la réforme , formule ta réponse sous la forme d'une liste a puce.

Réponds sans en-tête, sans guillemets.
"""
print("=== PROMPT ENVOYÉ ===\n", prompt)

proc = subprocess.run(
    ["ollama", "run", model_name],
    input=prompt,
    text=True,
    capture_output=True
)
if proc.returncode != 0:
    raise RuntimeError(f"Ollama erreur :\n{proc.stderr}")

response = proc.stdout.strip()
print("=== RÉPONSE DU MODÈLE ===\n", response)

if 'Position_Summary' in df.columns:
    df = df.drop(columns=['Position_Summary'])

insert_at = df.columns.get_loc(col_name) + 1
df.insert(insert_at, 'Position_Summary', "")
df.iat[0, insert_at] = response

df.to_excel(input_excel, index=False)
print("✅ Colonne 'Position_Summary' ajoutée, réponse insérée en ligne 1.")