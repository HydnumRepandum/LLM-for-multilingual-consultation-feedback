# -*- coding: utf-8 -*-
"""Consultation_NLP_imp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14nvffei27GrSJFFID8BYAV7wsV-S5Ivv
"""

from google.colab import drive
drive.mount('/content/drive')

"""Nous allons installer quelques librairies qui nous permettent d'utiliser l'accélération par GPU pour notre modèle."""

!apt-get update -y
!apt-get install -y pciutils lshw
!apt update && apt install -y lsof net-tools

"""En dessous vous retrouver le code necessaire a mettre dans un fichier pour adapter les hyperparametres du modele."""

###Pour le Model File

FROM gemma3:27b      # ← adaptez si besoin

# génération déterministe
PARAMETER temperature 0
# filtrage probabiliste (20 % de la probabilité cumulée)
PARAMETER top_p
# conserver les 40 tokens les plus probables
PARAMETER top_k
# pour parametre la taille de fenetre du modele
PARAMETER num_ctx 20000

#Passer par le terminal


curl -fsSL https://ollama.com/install.sh | sh


#Pour démarrer ollama
ollama serve & ollama pull gemma3:27b     #puis apres "control"+c
ollama serve & ollama pull gemma3:27b    #oui oui il faut bien le faire deux fois d'affiler pour une raison obscure.

#ollama serve & ollama pull llama3.3
#ollama serve & ollama pull llama3.3

#ollama serve & ollama pull qwen3:30b-a3b
#ollama serve & ollama pull qwen3:30b-a3b

#Il faut download le modelfile et le mettre dans le root,
#pour adapter les hyperparametres, temperature, top_k, top_p et surtout la fenetre de contexte

ollama create gemma3_det:latest -f Modelfile
ollama serve & ollama pull gemma3_det:latest

#ollama create llama3.3_det -f Modelfile
#ollama serve & ollama pull llama3.3_det

#ollama create qwen3:30b-a3b_det -f Modelfile
#ollama serve & ollama pull qwen3:30b-a3b_det

#pkill ollama pour reset le model

"""/content# ollama serve & ollama pull llama3.3
[2] 8371
[GIN] 2025/05/14 - 06:43:10 | 200 |     109.301µs |       127.0.0.1 | HEAD     "/"
Error: listen tcp 127.0.0.1:11434: bind: address already in use
pulling manifest ⠙ [GIN] 2025/05/14 - 06:43:10 | 200 |  298.677892ms |       127.0.0.1 | POST     "/api/pull"
pulling manifest
pulling 4824460d29f2: 100% ▕▏  42 GB                         
pulling 948af2743fc7: 100% ▕▏ 1.5 KB                         
pulling bc371a43ce90: 100% ▕▏ 7.6 KB                         
pulling 53a87df39647: 100% ▕▏ 5.6 KB                         
pulling 56bb8bd477a5: 100% ▕▏   96 B                         
pulling c7091aa45e9b: 100% ▕▏  562 B                         
verifying sha256 digest
writing manifest
success

En fonction du modèle choisi vous adapter le code
"""

model_name   = "gemma3_det:latest"   # ← adaptez si besoin

#model_name   = "llama3.3:latest"

#model_name   = "llama3.3_det"

#model_name   = "qwen3:30b-a3b_det"

"""Pour etre sur que le modele a été "pull" correctement nous allons faire un rapide test."""

import requests

resp = requests.post(
    "http://localhost:11434/api/generate",
    json={
        "model": "gemma3_det:latest",
        "prompt": """Ping!"""
    }
)

print("HTTP", resp.status_code)  # 200 = OK
print(resp.text[:500])           # affiche les 500 premiers caractères

"""Avant de commencer nous allons installer l'ensemble des librairies necessaires au fonctionnement de notre code."""

!pip install ocrmypdf PyPDF2 pdf2image pytesseract
!pip install pikepdf
!apt-get update -qq
!apt-get install -y -qq ghostscript tesseract-ocr
!pip install -q ocrmypdf
!pip install PyPDF2 langdetect
!pip install unpaper

import os
import re
from PyPDF2 import PdfWriter
from PyPDF2 import PdfReader
import ocrmypdf
import langdetect
from langdetect import detect_langs, LangDetectException
import matplotlib.pyplot as plt
from pathlib import Path
import subprocess
import pandas as pd
import json
import shutil
from tempfile import template
import unicodedata
import pikepdf
import logging
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np
import textwrap
import logging

"""**Première étape:** Nous allons prendre le fichier d'avis et nous allons faire un OCR dessus puis le découper en fonction de chaque partie prenante"""

# 1.1) Pour parvenir a notre OCR nous devons avant tout "désigner" le document initial


in_path  = '/content/drive/MyDrive/Consulation_NLP_imp/fedlex-data-admin-ch-eli-dl-proj-2024-5-cons_1-doc_7-fr-pdf-a.pdf'
tmp_path = '/content/drive/MyDrive/Consulation_NLP_imp/unsigned.pdf'

pdf = pikepdf.Pdf.open(in_path)
acro = pdf.Root.get("/AcroForm")
if acro and "/Fields" in acro:
    # ne garder que les champs non-signature
    fields = [f for f in acro.Fields if f.get("/FT") != "/Sig"]
    if fields:
        acro.Fields = fields
    else:
        del pdf.Root.AcroForm
pdf.save(tmp_path)

"""1) OCR sur le pdf des Avis"""

input_pdf  = '/content/drive/MyDrive/Consulation_NLP_imp/unsigned.pdf'
output_pdf = '/content/drive/MyDrive/Consulation_NLP_imp/ocr_output.pdf'

import ocrmypdf

ocrmypdf.ocr(
    input_pdf,
    output_pdf,
    force_ocr=True,
    output_type='pdf',
    deskew=True,
    clean=True,
    #remove_background=True,
    optimize=0,
    use_threads=True,
    jobs=4,
)

print(f"OCR’d PDF written to {output_pdf}")

"""2) Maintenant nous allons faire la découpe de notre pdf d'avis pour avoir les avis de chaque partie prenante en fonction de son affiliation (canton, faitieres, particulier) pour ce faire nous prendrons les signets deja présent au sein du document."""

reader = PdfReader('/content/drive/MyDrive/Consulation_NLP_imp/ocr_output.pdf')
outlines = reader.outline  # liste récursive d’objets Destination ou listes

def flatten(outlines, level=0):
    flat = []
    for o in outlines:
        if isinstance(o, list):
            flat += flatten(o, level+1)
        else:
            # o.title, o.page_number (0-indexé)
            flat.append((o.title, level, reader.get_destination_page_number(o)))
    return flat

entries = flatten(outlines)
# entries = [(“Chapitre 1”, 0, 0), (“1.1 Introduction”, 1, 2), …]
# 1) Base de sortie
base_out = os.path.expanduser('/content/drive/MyDrive/Consulation_NLP_imp/Extracted_Chapters')
os.makedirs(base_out, exist_ok=True)

# 2) Préparer liste triée par page
entries = sorted(entries, key=lambda x: x[2])

# 3) Parcours et découpe
for idx, (title, level, start) in enumerate(entries):
    # ne traiter que les niveaux 1 et 2 (chapitres et sous-chap.)
    if level not in (0,1): continue

    # déterminer la page de fin : page de l’entrée suivante au même ou plus petit niveau
    end = None
    for next_title, next_level, next_page in entries[idx+1:]:
        if next_level <= level:
            end = next_page
            break
    if end is None:
        end = len(reader.pages)

    # nettoyer le nom pour le système de fichiers
    safe = re.sub(r'[\\/:"*?<>|]+', '_', title).strip()
    if level == 0:
        chap_dir = os.path.join(base_out, safe)
        os.makedirs(chap_dir, exist_ok=True)
    else:
        # niveau 1 → sous‑chapitre
        chap_dir = os.path.join(base_out,
                                re.sub(r'[\\/:"*?<>|]+', '_', entries[[i for i,(t,l,p) in enumerate(entries) if i<idx and l==0][-1]][0]),
                                safe)
        os.makedirs(chap_dir, exist_ok=True)

    # écriture du PDF partiel
    writer = PdfWriter()
    for p in range(start, end):
        writer.add_page(reader.pages[p])

    out_path = os.path.join(chap_dir, f"{safe}.pdf")
    with open(out_path, 'wb') as f:
        writer.write(f)
    print(f"– Sauvé : {out_path} (pages {start+1}–{end})")

"""Maintenant que nous avons nos fichiers découpes nous allons pouvoirs commencer de faire nos analyses grace au NLP

Avant de commencer il faut que nous partagions nos fichiers en fonction de la langue dans laquelle ils sont rédigés.  En effet, le prompt que l'on appliquera sur eux devra etre dans la langue du document afin de garantir des résultats optimaux.
"""

# 2) Define your source and destination roots
src_root = Path('/content/drive/MyDrive/Consulation_NLP_imp/Extracted_Chapters').expanduser()
fr_root  = Path('/content/drive/MyDrive/Consulation_NLP_imp/Extracted_French').expanduser()
de_root  = Path('/content/drive/MyDrive/Consulation_NLP_imp/Extracted_German').expanduser()
it_root  = Path('/content/drive/MyDrive/Consulation_NLP_imp/Extracted_Italian').expanduser()

# 3) Walk through every PDF under src_root
for pdf_path in src_root.rglob('*.pdf'):
    try:
        reader = PdfReader(str(pdf_path))
        # extract text from the first few pages to speed up
        sample = ""
        for p in reader.pages[:3]:
            text = p.extract_text() or ""
            sample += text + "\n"
        # detect language probabilities
        langs = detect_langs(sample)
        top = langs[0]  # e.g. “fr:0.99”
        lang_code = top.lang
    except (LangDetectException, Exception) as e:
        # skip files we can’t read or detect
        print(f"⚠️ Skipping {pdf_path.name}: {e}")
        continue

    # decide destination based on highest‐scoring language
    if lang_code == 'fr':
        dest_tree = fr_root
    elif lang_code == 'de':
        dest_tree = de_root
    elif lang_code == 'it':
        dest_tree = it_root
    else:
        # ignore anything that isn’t clearly French or German
        continue

    # 4) Reconstruct the same relative path under the chosen root
    rel = pdf_path.relative_to(src_root)
    target = dest_tree / rel
    target.parent.mkdir(parents=True, exist_ok=True)
    shutil.copy2(pdf_path, target)
    print(f"→ {pdf_path.name}  →  {target}")

"""Nous allons pouvoir commencer notre analyse thématique.
Pour ce faire nous appliquerons un prompt a chaque texte et nous récuperons les réponses dans un fichier Excel.
Ensuite nous prenons l'ensemble de ces thématiques et nous appliquons une nouvelle analyse pour arriver a des grandes thématiques similaires entre acteurs et nous l'indiquons ensuite dans notre excel.

Nous allons faire cela pour chacune des langues nationales presentes dans les avis, a savoir l'italien, l'allemand et le francais. Une fois que cela sera fait nous regrouperons nos thématiques et nous les traduirons toutes en francais
"""

base_dir     = Path('/content/drive/MyDrive/Consulation_NLP_imp')
roots = {
    "FR": base_dir / "Extracted_French",
    "DE": base_dir / "Extracted_German",
    "IT": base_dir / "Extracted_Italian",
}
output_excel = base_dir / "ollama_outputs_with_thematics.xlsx"

# 3) Templates par langue (inchangés)
templates = {
    "FR": {
        "resume": (
            "Tu es un haut-fonctionnaire qui est mandaté pour produire un rapport de résultat "
            "sur un processus de consultation sur"
            " une réforme du code pénal. "
            "Veuillez produire un résumé clair et synthétique du document ci-dessous, "
            "en restituant fidèlement les idées principales et la progression argumentative :\n\n"
            "{texte}\n\n"
            "**Réponds** sans en-tête, sans guillemets, sans autre texte."
        ),
        "themes": (
            "Tu es un chercheur en sciences sociales, spécialiste en analyse thématique QUALITATIVE. "
            "À partir du texte fourni ci-dessous, réalise une **analyse thématique interprétative** "
            "en identifiant les **thématiques latentes** (valeurs, préoccupations, représentations) "
            "exprimées par l’acteur dans la procédure de consultation sur la réforme"
            "du code pénal \n\n"
            "Consignes strictes :\n"
            "- Donne uniquement une liste à puces.\n"
            "- Formule chaque thématique de façon concise (2 à 4 mots), au niveau interprétatif "
            "(valeurs/principes), et non contextuel.\n"
            "- Classe-les par ordre décroissant d’importance (poids discursif).\n"
            "- Ne donne ni titre, ni guillemets, ni texte explicatif.\n"
            "Texte à analyser :\n"
            "{texte}\n\n"
            "Thématiques latentes :"
        ),
    },
    "DE": {
        "resume": (
            "Du bist ein hoher Beamter, beauftragt, einen Ergebnisbericht über ein Konsultationsverfahren "
            "zur Reform des Strafgesetzbuches zu erstellen. Bitte erstelle eine klare und prägnante "
            "Zusammenfassung des untenstehenden Dokuments, die die Hauptgedanken und den "
            "Argumentationsverlauf originalgetreu wiedergibt:\n\n"
            "{texte}\n\n"
            "**Antworte** ohne Überschrift, ohne Anführungszeichen, ohne weiteren Text."
        ),
        "themes": (
            "Du bist ein Sozialwissenschaftler mit Spezialisierung auf QUALITATIVE thematische Analyse. "
            "Aus dem untenstehenden Text führe eine interpretative thematische Analyse durch, indem du "
            "die latenten Themen (Werte, Anliegen, Repräsentationen) identifizierst, die der Akteur im "
            "Konsultationsverfahren zur Reform des Strafgesetzbuches äußert.\n\n"
            "Strikte Anweisungen:\n"
            "- Gib ausschließlich eine Liste mit Aufzählungszeichen.\n"
            "- Formuliere jedes Thema prägnant (2–4 Wörter) auf interpretativer Ebene (Werte/Prinzipien), nicht kontextuell.\n"
            "- Ordne sie nach absteigender Wichtigkeit (diskursives Gewicht).\n"
            "- Gib weder Titel noch Anführungszeichen noch erklärenden Text.\n\n"
            "Zu analysierender Text:\n"
            "{texte}\n\n"
            "Latente Themen:"
        ),
    },
    "IT": {
        "resume": (
            "Sei un alto funzionario incaricato di redigere un rapporto sui risultati di un processo di consultazione "
            "sulla riforma del codice penale. Genera un riassunto chiaro e sintetico del documento seguente, "
            "restituendo fedelmente le idee principali e il percorso argomentativo:\n\n"
            "{texte}\n\n"
            "**Rispondi** senza intestazione, senza virgolette, senza altro testo."
        ),
        "themes": (
            "Sei un ricercatore in scienze sociali, specialista in analisi tematica QUALITATIVA. "
            "A partire dal testo fornito di seguito, esegui un'analisi tematica interpretativa identificando "
            "i temi latenti (valori, preoccupazioni, rappresentazioni) espressi dall’attore nella procedura "
            "di consultazione sulla riforma del codice penale.\n\n"
            "Istruzioni rigorose:\n"
            "- Fornisci esclusivamente un elenco puntato.\n"
            "- Formula ogni tema in modo conciso (2–4 parole) a livello interpretativo (valori/principi), non contestuale.\n"
            "- Ordinali in ordine decrescente di importanza (peso discorsivo).\n"
            "- Non includere titoli, virgolette o testi esplicativi.\n\n"
            "Testo da analizzare:\n"
            "{texte}\n\n"
            "Temi latenti:"
        ),
    },
}


results = []
for lang, folder in roots.items():
    if not folder.exists():
        print(f"⚠️ Dossier introuvable pour {lang}: {folder}")
        continue
    tpl = templates[lang]
    for pdf_path in folder.rglob("*.pdf"):
        # extraction et snippet
        reader    = PdfReader(str(pdf_path))
        full_text = "\n".join(page.extract_text() or "" for page in reader.pages)

        # --- Étape 1 : résumé ---
        prompt_sum = tpl["resume"].format(texte=full_text)
        print("\n=== PROMPT RÉSUMÉ ===\n", prompt_sum)

        proc_sum = subprocess.run(
            ["ollama", "run", model_name],
            input=prompt_sum, text=True, capture_output=True
        )
        print("=== STDOUT RÉSUMÉ ===\n", proc_sum.stdout)

        if proc_sum.returncode != 0:
            print(f"⚠️ Résumé échoué ({lang}) pour {pdf_path.name}")
            summary = ""
        else:
            summary = proc_sum.stdout.strip()

        # --- Étape 2 : thématiques ---
        prompt_them = tpl["themes"].format(texte=full_text)
        print("\n=== PROMPT THÉMATIQUES ===\n", prompt_them)

        proc_them = subprocess.run(
            ["ollama", "run", model_name],
            input=prompt_them, text=True, capture_output=True
        )
        print("=== STDOUT THÉMATIQUES ===\n", proc_them.stdout)

        if proc_them.returncode != 0:
            print(f"⚠️ Thématiques échouées ({lang}) pour {pdf_path.name}")
            thematics = ""
        else:
            thematics = proc_them.stdout.strip()

        results.append({
            "lang":      lang,
            "filename":  pdf_path.name,
            "summary":   summary,
            "thematics": thematics
        })

# 6) Sauvegarde
df = pd.DataFrame(results)
df.to_excel(output_excel, index=False)
print("✅ Résultats enregistrés dans :", output_excel)
print(df.head())

"""Maintenant nous allons traduire les themes des differents avis afin que nous puissons les proceder de maniere unis par la suite"""

# 1) Chemins
base_dir     = Path('/content/drive/MyDrive/Consulation_NLP_imp')
input_excel  = base_dir / "ollama_outputs_with_thematics.xlsx"
output_excel = base_dir / "ollama_outputs_with_thematics.xlsx"

# 2) Charger l’Excel
df = pd.read_excel(input_excel)
print("➡️ Colonnes disponibles :", df.columns.tolist())

# 3) Template de traduction
translate_template = (
    "Veuillez traduire en français la liste de thèmes suivante, "
    "en conservant la structure en liste à puces si présente, "
    "et en veillant à ce que le contenu soit clair et précis :\n\n"
    "{thematics}\n\n"
    "**Réponds** sans en-tête, sans guillemets, sans autre texte."
    "Thèmes en français :"
)


# 4) Fonction de traduction
def translate_thematics(text):
    if not text.strip():
        return ""  # rien à traduire
    prompt = translate_template.format(thematics=text)
    # Affichage du prompt
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt, text=True, capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Échec pour «{text[:30]}…»\n", proc.stderr.strip())
        return ""
    response = proc.stdout.strip()
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)

    return proc.stdout.strip()

# 5) Appliquer la traduction
df['thematics_fr'] = df['thematics'].astype(str).apply(translate_thematics)

# 6) Sauvegarder
df.to_excel(output_excel, index=False)
print("✅ Colonnes traduites ajoutées et fichier enregistré dans :", output_excel)

# 1) Chemins & paramètres
base_dir    = Path('/content/drive/MyDrive/Consulation_NLP_imp')
input_file  = base_dir / "ollama_outputs_with_thematics.xlsx"
col_name    = "thematics_fr"

# 2) Charger le DataFrame
df = pd.read_excel(input_file)

# 3) Construire et afficher le prompt
texts    = df[col_name].dropna().astype(str).tolist()
numbered = "\n".join(f"{i+1}. {t}" for i,t in enumerate(texts,1))
prompt   = f"""\
Tu es un chercheur en sciences sociales, spécialiste en analyse thématique qualitative.
Voici la liste complète des thématique extraits de la colonne « {col_name} » :
{numbered}

Effectue un regroupement en exactement 5 catégories thématiques représentatives et distinguables.
**Réponds** sans en-tête, sans guillemets, sous la forme :
<catégorie> : description de la catégorie
"""
print("=== PROMPT ENVOYÉ ===\n", prompt)

# 4) Appel Ollama
proc     = subprocess.run(
    ["ollama","run",model_name],
    input=prompt,
    text=True,
    capture_output=True
)
if proc.returncode != 0:
    raise RuntimeError(f"Ollama erreur :\n{proc.stderr}")
response = proc.stdout.strip()
print("=== RÉPONSE DU MODÈLE ===\n", response)

# 5) Supprimer l’ancienne colonne si elle existe
if 'general_theme_codebook' in df.columns:
    df = df.drop(columns=['general_theme_codebook'])

# 6) Insérer la nouvelle colonne juste après 'thematics_fr'
insert_at = df.columns.get_loc(col_name) + 1
df.insert(insert_at, 'general_theme_codebook', "")

# 7) Placer la réponse du modèle dans la première cellule sous le header
df.iat[0, insert_at] = response

# 8) Enregistrer
df.to_excel(input_file, index=False)
print("✅ Colonne 'general_theme_codebook' ajoutée, réponse insérée en ligne 1.")

"""On sépare les thematiques de leurs descriptions dans une nouvelle colonne"""

def extract_themes(cell):
    # On transforme en chaîne et on découpe sur tout type de saut de ligne
    lines = re.split(r'[\r\n]+', str(cell))
    themes = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if ':' in line:
            theme, _ = line.split(':', 1)
            themes.append(theme.strip())
        else:
            # Cas où il n’y a pas de “:”
            themes.append(line)
    return themes

# 3) Appliquer et créer une colonne de listes
df['general_theme_fr'] = df['general_theme_codebook'].apply(extract_themes)
df["general_theme_fr"] = df["general_theme_fr"].apply(lambda lst: "\n".join(lst))

# 4) Save back to Excel
df.to_excel(input_file, index=False)

"""Pour éviter tout probleme d'hallucination de notre modele nous rajoutons la catégorie neutre dans notre cellule de thématiques générales."""

ancienne_valeur = df.at[0, "general_theme_codebook"]
if pd.isna(ancienne_valeur):
    ancienne_valeur = ""


df.at[0, "general_theme_fr"] = f"{ancienne_valeur} \\nAucun de ces thèmes: le document ne correspond a aucun des autres thèmes mentionnés"

# 4. Sauvegarder dans un nouveau fichier (ou écraser l’existant)
df.to_excel(input_file, index=False)

"""Pour traduire les themes generaux en allemand et italien pour pouvoir apres les appliquer sur les textes"""

col_name = "general_theme_fr"

# 2) Charger l’Excel
df = pd.read_excel(input_excel)

# 3) Template de traduction
translate_template = (
    "Bitte übersetzen Sie die folgende Themenliste ins Deutsche, "
    "unter Beibehaltung der Aufzählungsstruktur, falls vorhanden, "
    "und achten Sie darauf, dass der Inhalt klar und präzise ist:\n\n"
    "{thematics}\n\n"
    "**beantworte** ohne Überschrift, ohne Anführungszeichen, ohne weiteren Text. "
    "Themen auf Deutsch:"
)

# 4) Fonction de traduction
def translate_thematics(general_theme_fr):
    if not general_theme_fr.strip():
        return ""  # rien à traduire
    prompt = translate_template.format(thematics=general_theme_fr)
    # Affichage du prompt
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt,
        text=True,
        capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Échec pour «{theme_fr[:30]}…» : {proc.stderr.strip()}")
        return ""
    response = proc.stdout.strip()
    # Affichage de la réponse
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)
    return response

# 5) Appliquer la traduction
translated = df[col_name].fillna("").astype(str).apply(translate_thematics)

# 6) Insérer la nouvelle colonne juste après 'general_theme_fr'
if 'general_theme_de' in df.columns:
    df = df.drop(columns=['general_theme_de'])
insert_at = df.columns.get_loc(col_name) + 1
# On insère directement la série traduite
df.insert(insert_at, 'general_theme_de', translated)

# 7) Enregistrer
df.to_excel(output_excel, index=False)
print(f"✅ Colonne 'general_theme_de' ajoutée, réponses enregistrées dans {output_excel}")

col_name = "general_theme_fr"

# 3) Template de traduction
translate_template = (
    "Traduci il seguente elenco di temi in italiano, "
    "mantenendo la struttura dell'elenco puntato, se presente, "
    "e assicurandoti che il contenuto sia chiaro e preciso:\n\n"
    "{thematics}\n\n"
    "**rispondi** senza titoli, senza virgolette, senza altro testo aggiuntivo. "
    "Temi in italiano:"
)

# 4) Fonction de traduction
def translate_thematics(general_theme_fr):
    if not general_theme_fr.strip():
        return ""  # rien à traduire
    prompt = translate_template.format(thematics=general_theme_fr)
    # Affichage du prompt
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt,
        text=True,
        capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Échec pour «{theme_fr[:30]}…» : {proc.stderr.strip()}")
        return ""
    response = proc.stdout.strip()
    # Affichage de la réponse
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)
    return response

# 5) Appliquer la traduction
translated = df[col_name].fillna("").astype(str).apply(translate_thematics)

# 6) Insérer la nouvelle colonne juste après 'general_theme_fr'
if 'general_theme_it' in df.columns:
    df = df.drop(columns=['general_theme_it'])
insert_at = df.columns.get_loc(col_name) + 1
# On insère directement la série traduite
df.insert(insert_at, 'general_theme_it', translated)

# 7) Enregistrer
df.to_excel(output_excel, index=False)
print(f"✅ Colonne 'general_theme_it' ajoutée, réponses enregistrées dans {output_excel}")

# 1) Chemins & paramètres
base_dir = Path('/content/drive/MyDrive/Consulation_NLP_imp')
input_excel = base_dir / "ollama_outputs_with_thematics.xlsx"
# On réécrit dans le même fichier
output_excel = input_excel
roots = {
    "FR": base_dir / "Extracted_French",
    "DE": base_dir / "Extracted_German",
    "IT": base_dir / "Extracted_Italian",
}

# 2) Charger la liste des thèmes généraux
# (utile pour le prompt)
df = pd.read_excel(input_excel)
general_themes = {}
for lang in ["FR", "DE", "IT"]:
    col = f"general_theme_{lang.lower()}"
    if col not in df.columns:
        raise KeyError(f"Colonne manquante dans Excel: {col}")
    themes = df[col].dropna().unique().tolist()
    general_themes[lang] = ", ".join(themes)

# 3) Templates par langue
prompt_template = {
    "FR": (
        "Tu es un chercheur en sciences sociales, spécialiste en analyse thématique qualitative.\n"
        "Pour chaque document, indique **uniquement** le thème général correspondant.\n\n"
        "Texte à analyser:\n{texte}\n\n"
        "Thèmes généraux possibles : {general}\n\n"
        "Réponds **exactement** par la seule catégorie choisie (pas de CSV, pas de JSON)."
    ),
    "DE": (
        "Du bist ein Sozialwissenschaftler mit Spezialisierung auf qualitative thematische Analyse.\n"
        "Gib für jedes Dokument **ausschließlich** das zutreffende allgemeine Thema an.\n\n"
        "Zu analysierender Text:\n{texte}\n\n"
        "Mögliche allgemeine Themen : {general}\n\n"
        "Antworte **exakt** mit der ausgewählten Kategorie (kein CSV, kein JSON)."
    ),
    "IT": (
        "Sei un ricercatore in scienze sociali, specialista nell'analisi tematica qualitativa.\n"
        "Per ogni documento, indica **esclusivamente** il tema generale corrispondente.\n\n"
        "Testo da analizzare:\n{texte}\n\n"
        "Possibili temi generali  : {general}\n\n"
        "Rispondi **esattamente** indicando solo la categoria scelta (no CSV, no JSON)."
    )
}

# 4) Fonction de catégorisation
def categorize_document(full_text: str, template: str, general_list: str) -> str:
    prompt = template.format(texte=full_text, general=general_list)
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt,
        text=True,
        capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Erreur : {proc.stderr.strip()}")
        return ""
    response = proc.stdout.strip()
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)
    return response.splitlines()[0] if response else ""

# 5) Parcours des PDFs et classification
# On crée une nouvelle colonne pour stocker la catégorie de chaque document traité
categories = []
files = []
langs = []
for lang, folder in roots.items():
    if not folder.exists():
        continue
    template = prompt_template[lang]
    general_list = general_themes[lang]
    for pdf_path in folder.rglob("*.pdf"):
        reader = PdfReader(str(pdf_path))
        full_text = "\n".join(page.extract_text() or "" for page in reader.pages)
        category = categorize_document(full_text, template, general_list)
        files.append(pdf_path.name)
        langs.append(lang)
        categories.append(category)
# On crée/écrase la colonne 'general_category'
df['general_category'] = pd.Series(categories, index=df.index[:len(categories)])

# 7) Enregistrer dans le même fichier
df.to_excel(output_excel, index=False)
print(f"✅ Colonnes ajoutées et mis à jour dans : {output_excel}")

# 2) Charger le DataFrame
df = pd.read_excel(input_excel)
print("➡️ Colonnes disponibles :", df.columns.tolist())

# 3) Template de traduction
translate_template = (
    "Veuillez traduire en français le thème suivant"
    ":\n\n"
    "{category}\n\n"
    "**Réponds** sans en-tête, sans guillemets, sans autre texte. "
    "Thème en français :"
)

# 4) Fonction de traduction
def translate_category(category: str) -> str:
    if not category.strip():
        return ""  # Rien à traduire
    prompt = translate_template.format(category=category)
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt,
        text=True,
        capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Échec pour «{category[:30]}…» : {proc.stderr.strip()}")
        return ""
    response = proc.stdout.strip()
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)
    return response

# 5) Appliquer la traduction ligne par ligne sur la colonne 'general_category'
df['category_fr'] = df['general_category'].fillna("").astype(str).apply(translate_category)

# 6) Enregistrer dans le même fichier
df.to_excel(output_excel, index=False)
print(f"✅ Traductions enregistrées dans : {output_excel}")

"""Dans le cas ou on fait usage d'un modèle agentique (comme Qwen3) , il est necessaire que nous supprimions l'ensemble de la phase de raisonnement du modèle présent dans ces réponses

On sépare les thematiques de leurs descriptions dans une nouvelle colonne
"""

def extract_themes(cell):
    # On transforme en chaîne et on découpe sur tout type de saut de ligne
    lines = re.split(r'[\r\n]+', str(cell))
    themes = []
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if ':' in line:
            theme, _ = line.split(':', 1)
            themes.append(theme.strip())
        else:
            # Cas où il n’y a pas de “:”
            themes.append(line)
    return themes

# 3) Appliquer et créer une colonne de listes
df['general_theme_fr'] = df['general_theme_codebook'].apply(extract_themes)
df["general_theme_fr"] = df["general_theme_fr"].apply(lambda lst: "\n".join(lst))

# 4) Save back to Excel
df.to_excel(input_file, index=False)

theme_col = 'category_fr'

df = df.dropna(subset=[theme_col])
themes = df[theme_col].tolist()

# 2. Compute embeddings using a pretrained model
# Choice of embedding model: "all-MiniLM-L6-v2"
model = SentenceTransformer('all-MiniLM-L6-v2')
theme_embeddings = model.encode(themes)

# 3. Calculate pairwise cosine similarity
similarity_matrix = cosine_similarity(theme_embeddings)

# Set diagonal to 0 to ignore self-similarity
np.fill_diagonal(similarity_matrix, 0)

# 4. Merge themes based on similarity threshold (0.80 - 0.99)
similarity_threshold_low = 0.80
similarity_threshold_high = 0.999

# Create a mapping for merged themes
theme_map = dict()

for idx, theme in enumerate(themes):
    if theme in theme_map:
        continue

    # Find indices where similarity is within threshold
    similar_idxs = np.where(
        (similarity_matrix[idx] >= similarity_threshold_low) &
        (similarity_matrix[idx] <= similarity_threshold_high)
    )[0]

    # Merge themes into the most frequent canonical theme
    candidates = [themes[i] for i in similar_idxs] + [theme]
    canonical = df[df[theme_col].isin(candidates)][theme_col].value_counts().idxmax()

    for candidate in candidates:
        theme_map[candidate] = canonical

# Apply merging
df['cleaned_theme'] = df[theme_col].map(theme_map)

# 5. Recount theme frequencies after cleaning
cleaned_counts = df['cleaned_theme'].value_counts()

# --- Graph Styling (Themes Only) ---
fig, ax = plt.subplots(figsize=(10, 10))
explode = [0.05] * len(cleaned_counts)

wedges, texts, autotexts = ax.pie(
    cleaned_counts,
    autopct='%1.1f%%',
    startangle=140,
    explode=explode,
    pctdistance=0.75,
    wedgeprops={'linewidth': 1, 'edgecolor': 'white'}
)

ax.set(aspect="equal")
ax.set_title(
    f"Distribution of thematics\n Number of responses : {cleaned_counts.sum()}",
    fontsize=16,
    pad=30
)

legend_labels = ["\n".join(textwrap.wrap(cat, width=15)) for cat in cleaned_counts.index]

legend = ax.legend(
    wedges,
    legend_labels,
    title="Thematics",
    loc="center left",
    bbox_to_anchor=(1.02, 0.5),
    fontsize=9,
    title_fontsize=12,
    ncol=3,
    frameon=True,
    shadow=True,
    facecolor='white',
    framealpha=0.8,
    edgecolor='gray',
    borderpad=1,
    handlelength=1.2,
    handletextpad=0.5,
    columnspacing=2.5,
    labelspacing=1.2
)
legend.get_frame().set_boxstyle('round,pad=0.5')

plt.tight_layout()
plt.show()

# --- Second Graph (Themes with Actors) ---
actors_by_cat = df.groupby('cleaned_theme')['filename'].apply(list)

fig, ax = plt.subplots(figsize=(10, 10))

wedges, texts, autotexts = ax.pie(
    cleaned_counts,
    autopct='%1.1f%%',
    startangle=140,
    explode=explode,
    pctdistance=0.75,
    wedgeprops={'linewidth': 1, 'edgecolor': 'white'}
)

ax.set(aspect="equal")
ax.set_title(
    f"Distribution of thematics\n Number of responses : {cleaned_counts.sum()}",
    fontsize=16,
    pad=30
)

def wrap_label(cat):
    cat_wrapped = "\n".join(textwrap.wrap(cat, width=15))
    acteurs = actors_by_cat.get(cat, [])
    details_wrapped = "\n".join(textwrap.wrap(", ".join(acteurs), width=20))
    label = rf"{{{cat_wrapped}}} : {len(acteurs)}"
    if acteurs:
        label += "\n" + details_wrapped
    return label

legend_labels = [wrap_label(cat) for cat in cleaned_counts.index]

legend = ax.legend(
    wedges,
    legend_labels,
    title="Thematics and actors",
    loc="center left",
    bbox_to_anchor=(1.02, 0.5),
    fontsize=9,
    title_fontsize=12,
    ncol=3,
    frameon=True,
    shadow=True,
    facecolor='white',
    framealpha=0.8,
    edgecolor='gray',
    borderpad=1,
    handlelength=1.2,
    handletextpad=0.5,
    columnspacing=2.5,
    labelspacing=1.2
)
legend.get_frame().set_boxstyle('round,pad=0.5')

plt.tight_layout()
plt.show()

# Save the figure
output_dir = './graphs'
os.makedirs(output_dir, exist_ok=True)
output_path = os.path.join(output_dir, "distribution_cleaned_themes_actors.pdf")
fig.savefig(output_path, bbox_inches="tight")
plt.close()

print(f"✅ Graphique enregistré dans : {output_path}")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


output_excel = base_dir / "ollama_outputs_with_thematics.xlsx"

file_map = {}
for lang, folder in roots.items():
    if not folder.exists():
        logger.warning(f"Dossier non trouvé: {folder}")
        file_map[lang] = {}
    else:
        lang_map = {}
        for p in folder.rglob("*.pdf"):
            name_norm = unicodedata.normalize("NFC", p.name)
            lang_map[name_norm] = p
        file_map[lang] = lang_map
        logger.info(f"{lang}: {len(lang_map)} fichiers PDF indexés")

# --- Chargement ou initialisation du DataFrame ---
if output_excel.exists():
    df = pd.read_excel(output_excel, engine="openpyxl")
    df.columns = df.columns.str.strip().str.lower()
    for col in ["lang", "filename", "volet1", "avis"]:
        if col not in df.columns:
            df[col] = None
    df.rename(columns={"avis": "Avis"}, inplace=True)
else:
    records = []
    for lang, files in file_map.items():
        for fname in files:
            records.append({"lang": lang, "filename": fname, "volet1": None, "Avis": None})
    df = pd.DataFrame(records)
    logger.info(f"DataFrame initialisé avec {len(df)} lignes")

# --- Templates simplifiés pour trois langues ---
templates_simple = {
    "FR": (
        "Tu es un haut-fonctionnaire chargé de produire un rapport de consultation sur une réforme du code pénal.\n"
        "Pour chaque avis d'acteur sur cet objet , indiquez si l'avis est positif, négatif ou neutre.\n"
        "Répond **UNIQUEMENT** par un seul mot parmi : « positif », « neutre » ou « négatif ».\n\n"
        "Objet :\n"
        "Ajouter l'assassinat à la liste des infractions imprescriptibles dans le code pénal et le code pénal militaire.\n\n"
        "Avis à analyser :\n{texte}"
    ),
    "DE": (
        "Du bist ein hoher Beamter, der beauftragt wurde, einen Konsultationsbericht über eine Reform des Strafgesetzbuches zu erstellen.\n"
        "Für jede Stellungnahme eines Akteurs zu diesem Gegenstand gib an, ob die Stellungnahme positiv, negativ oder neutral ist.\n"
        "Antworte **AUSSCHLIESSLICH** mit einem einzigen Wort: „positiv“, „neutral“ oder „negativ“.\n\n"
        "Gegenstand:\n"
        "Ergänzung des Mordes in die Liste der nicht verjährbaren Straftaten im Strafgesetzbuch und im Militärstrafgesetzbuch.\n\n"
        "Stellungnahme zur Analyse:\n"
        "{texte}"
    ),
    "IT": (
        "Sei un alto funzionario incaricato di redigere un rapporto di consultazione su una riforma del codice penale.\n"
        "Per ciascun parere di un attore su questo oggetto, indica se il parere è positivo, negativo o neutro.\n"
        "Rispondi **ESCLUSIVAMENTE** con una sola parola tra: “positivo”, “neutro” o “negativo”.\n\n"
        "Oggetto:\n"
        "Aggiungere l'omicidio all'elenco dei reati imprescrittibili nel codice penale e nel codice penale militare.\n\n"
        "Parere da analizzare:\n"
        "{texte}"
    ),
}

# --- Valeurs acceptées par langue et nombre de tentatives ---
allowed_map = {
    "FR": {"positif", "neutre", "négatif"},
    "DE": {"positiv", "neutral", "negativ"},
    "IT": {"positivo", "neutro", "negativo"},
}
MAX_RETRIES = 3
SAVE_INTERVAL = 1


# --- Fonction d'extraction de texte PDF ---
def extract_text(pdf_path: Path) -> str:
    reader = PdfReader(str(pdf_path))
    return "\n".join(page.extract_text() or "" for page in reader.pages)

# --- Boucle principale de traitement ---
for idx, row in df.iterrows():
    if pd.notna(row.get("volet1")):
        continue

    lang = row["lang"]
    fname = unicodedata.normalize("NFC", str(row["filename"]).strip())
    pdf_path = file_map.get(lang, {}).get(fname)
    if not pdf_path:
        logger.error(f"Fichier introuvable : {lang}/{fname}")
        continue

    logger.info(f"Traitement de {lang}/{fname} (index {idx})")
    full_text = extract_text(pdf_path)
    prompt = templates_simple[lang].format(texte=full_text)

    # Tentatives de classification
    for attempt in range(1, MAX_RETRIES + 1):
        proc = subprocess.run(
            ["ollama", "run", model_name],
            input=prompt,
            text=True,
            capture_output=True
        )
        resp = proc.stdout.strip().lower()
        print("\n=== PROMPT ENVOYÉ ===")
        print(prompt)
        print("=== RÉPONSE DU MODÈLE ===")
        print(resp)

        if resp in allowed_map[lang]:
            df.at[idx, "volet1"] = resp
            df.at[idx, "Avis"] = resp
            logger.info(f"Réponse valide au tour {attempt} : {resp}")
            break
        else:
            logger.warning(f"Tentative {attempt} invalide : «{resp}»")
            df.at[idx, "volet1"] = None
            df.at[idx, "Avis"] = None
    else:
        logger.error(f"Échec après {MAX_RETRIES} essais pour l’index {idx}")

    # Sauvegarde incrémentale
    if idx % SAVE_INTERVAL == 0 and idx > 0:
        try:
            df.to_excel(output_excel, index=False, engine="openpyxl")
            logger.info(f"Sauvegarde intermédiaire à l’index {idx}")
        except Exception as e:
            logger.error(f"Erreur lors de la sauvegarde intermédiaire : {e}")

# --- Sauvegarde finale ---
try:
    df.to_excel(output_excel, index=False, engine="openpyxl")
    logger.info(f"Fichier sauvegardé : {output_excel}")
except Exception as e:
    logger.error(f"Erreur lors de l'écriture du fichier final : {e}")

print("✅ Traitement terminé.")

translation_map = {
    # Allemand
    "positiv":  "positif",
    "negativ":  "négatif",
    "neutral":  "neutre",
    # Italien
    "positiva": "positif",
    "negativo": "négatif",
    "neutrale": "neutre",
    # Français (au cas où)
    "positif":  "positif",
    "negatif":  "négatif",
    "neutre":   "neutre"
}

# 2) Normaliser la casse
df['volet1_norm'] = df['volet1'].str.strip().str.lower()


# 3) Appliquer la traduction
df['volet1_fr'] = df['volet1_norm'].map(translation_map).fillna(df['volet1'])


# 4) Nettoyage (supprimer les colonnes intermédiaires si vous le souhaitez)
df.drop(columns=['volet1_norm'], inplace=True)

# 5) (Optionnel) pour vérifier
print(df[['filename','volet1','volet1_fr']].head())

# 6) Ensuite, vous pouvez ré-enregistrer votre fichier Excel
df.to_excel(input_excel, index=False)

# 1) Préparation du dossier de sortie
output_dir = '/content/drive/MyDrive/Consulation_NLP_imp/Graph'
os.makedirs(output_dir, exist_ok=True)

for volet in ['volet1_fr']:
    counts = df[volet].value_counts()
    actors_by_cat = df.groupby(volet)['filename'].apply(list)
    total_responses = counts.sum()

    # 2) Création de la figure
    fig, ax = plt.subplots(figsize=(10, 10))
    explode = [0.05] * len(counts)

    # --- Définition des couleurs par catégorie
    color_map = {
        'négatif': 'red',
        'positif': 'green',
        'neutre': 'lightblue'
    }
    # si vous avez d'autres labels, ils prendront une couleur par défaut
    default_color = 'gray'
    colors = [color_map.get(cat, default_color) for cat in counts.index]

    # 3) Tracé du camembert avec palette personnalisée
    wedges, texts, autotexts = ax.pie(
        counts,
        autopct='%1.1f%%',
        startangle=140,
        explode=explode,
        pctdistance=0.75,
        wedgeprops={'linewidth': 1, 'edgecolor': 'white'},
        colors=colors
    )

    # 4) Aspect circulaire et titre
    ax.set(aspect="equal")
    ax.set_title(
        f"Number of response: {total_responses}",
        fontsize=16,
        pad=30
    )

    # 5) Wrapping + mise en gras de la catégorie
    def wrap_label(cat):
        details = ", ".join(actors_by_cat[cat])
        wrapped = "\n".join(textwrap.wrap(details, width=20))
        return (
            rf"$\mathbf{{{cat}}}$: {len(actors_by_cat[cat])}"
            + "\n(" + wrapped + ")"
        )

    legend_labels = [wrap_label(cat) for cat in counts.index]

    # 6) Légende stylée en 3 colonnes, avec shadow=True
    legend = ax.legend(
        wedges,
        legend_labels,
        title="Opinion of Actors",
        loc="center left",
        bbox_to_anchor=(1.02, 0.5),
        fontsize=9,
        title_fontsize=12,
        ncol=3,
        frameon=True,
        shadow=True,
        facecolor='white',
        framealpha=0.8,
        edgecolor='gray',
        borderpad=1,
        handlelength=1.2,
        columnspacing=1.5
    )
    legend.get_frame().set_boxstyle('round,pad=0.5')

    plt.tight_layout()
    plt.show()

    # 7) Sauvegarde
    output_path = os.path.join(output_dir, f"repartition_{volet}.pdf")
    fig.savefig(output_path, bbox_inches='tight')
    plt.close()

print(f"✅ Graphiques enregistrés dans : {output_dir}")

"""Maintenant nous essayons de develloper un prompt qui permet de voir les propositions de modification qui sont proposées par les differentes parties prenantes"""

import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# --- Prompt templates ---
templates = {
    "FR": {
        "Amendement": (
            "Tu es un haut-fonctionnaire mandaté pour produire un rapport sur la réforme du "
            "code pénal en Suisse.\n"
            "Tu recevras **un avis de partie prenante à la fois**. Pour chaque avis, fais :\n"
            "1. **Extrais uniquement les propositions de modification** sous forme de liste à puces.\n"
            "2. Pour chaque proposition : reformulation concise, catégorie, référence précise.\n"
            "3. **Pas d'autre commentaire**.\n\n"
            "**Texte :** {texte}"
        )
    },
    "DE": {
        "Amendement": (
            """\
Du bist ein hoher Beamter, der beauftragt wurde, einen Bericht über die Reform des Strafgesetzbuches in der Schweiz zu erstellen.
Du wirst **jeweils nur eine Stellungnahme von Stakeholdern** erhalten. Für jede Stellungnahme führe Folgendes aus:

1. **Extrahiere ausschließlich die Änderungsvorschläge** und gib sie als Aufzählungsliste wieder.
2. Für jeden Vorschlag:
   - prägnante Umformulierung
   - Kategorie
   - genaue Referenz
3. **Keinen weiteren Kommentar**.

**Text:** {texte}"""
        )
    },
    "IT": {
        "Amendement": (
            """\
Sei un alto funzionario incaricato di redigere un rapporto sulla riforma del codice penale in Svizzera.
Riceverai **un parere di stakeholder alla volta**. Per ciascun parere esegui:

1. **Estrai esclusivamente le proposte di modifica** e riportale come elenco puntato.
2. Per ogni proposta:
   - riformulazione concisa
   - categoria
   - riferimento preciso
3. **Nessun altro commento**.

**Testo:** {texte}"""
        )
    },
}

# --- Load existing results if any ---
if output_excel.exists():
    try:
        df_existing = pd.read_excel(output_excel)
        logger.info("Loaded existing results from %s", output_excel)
    except Exception as e:
        logger.error("Failed to read existing Excel: %s", e)
        df_existing = pd.DataFrame(columns=["filename", "Amendement"])
else:
    df_existing = pd.DataFrame(columns=["filename", "Amendement"])

# --- Helper functions ---
def extract_text_from_pdf(path: Path) -> str:
    """Lit et concatène le texte de chaque page du PDF."""
    try:
        reader = PdfReader(str(path))
        texts = [page.extract_text() or "" for page in reader.pages]
        full = "\n".join(texts)
        return full
    except Exception as e:
        logger.warning("Erreur lors de l'extraction de texte pour %s: %s", path, e)
        return ""

print("\n=== PROMPT ENVOYÉ ===")
print(prompt)
def call_llm(prompt: str) -> str:
    """Appel subprocess à l'LLM et retourne la sortie."""
    try:
        proc = subprocess.run(
            ["ollama", "run", model_name],
            input=prompt,
            text=True,
            capture_output=True,
            check=True,
        )
        return proc.stdout.strip()
    except subprocess.CalledProcessError as e:
        logger.error("LLM call failed: %s", e.stderr)
        return ""
        response = proc.stdout.strip()
        print("=== RÉPONSE DU MODÈLE ===")
        print(response)

# --- Main processing ---
amend_dict = {}
for lang, folder in roots.items():
    if lang not in templates:
        logger.warning("No template for language %s, skipping", lang)
        continue
    tpl = templates[lang]["Amendement"]
    for pdf_path in folder.rglob("*.pdf"):
        logger.info("Processing %s", pdf_path.name)
        text = extract_text_from_pdf(pdf_path)
        if not text.strip():
            logger.warning("No text extracted for %s, skipping LLM", pdf_path.name)
            amend_dict[pdf_path.name] = ""
            continue
        # Optionally chunk text if too long for prompt
        prompt = tpl.format(texte=full_text)
        result = call_llm(prompt)
        amend_dict[pdf_path.name] = result

# --- Build/update DataFrame ---
if not df_existing.empty:
    df_existing.set_index("filename", inplace=True)
    df_existing["Amendement"] = pd.Series(amend_dict)
    df_final = df_existing.reset_index()
else:
    df_final = pd.DataFrame(
        [{"filename": fname, "Amendement": a} for fname, a in amend_dict.items()]
    )

# --- Save results ---
try:
    df_final.to_excel(output_excel, index=False)
    logger.info("Results saved to %s", output_excel)
except Exception as e:
    logger.error("Failed to write Excel: %s", e)

# For quick check
print(df_final.head())

"""Pour finaliser notre analyse nous allons demander un avis général a notre modele sur l'ensemble du processus de consultation en utilisant les résumés produits."""

#Nous allons pour l'instant traduire les résumés en francais pour assurer la coherence du texte pour le modele.



# 1) Chemins
base_dir     = Path('/content/drive/MyDrive/Consulation_NLP_imp')
input_excel  = base_dir / "ollama_outputs_with_thematics.xlsx"
output_excel = base_dir / "ollama_outputs_with_thematics.xlsx"

# 3) Template de traduction
translate_template = (
    "Veuillez traduire en français ce court texte en veillant à ce que le contenu soit clair et précis :\n\n"
    "{summary}\n\n"
    "**Réponds** sans en-tête, sans guillemets, sans autre texte."
    "texte en français :"
)


# 4) Fonction de traduction
def translate_thematics(text):
    if not text.strip():
        return ""  # rien à traduire
    prompt = translate_template.format(summary=text)
    # Affichage du prompt
    print("\n=== PROMPT ENVOYÉ ===")
    print(prompt)
    proc = subprocess.run(
        ["ollama", "run", model_name],
        input=prompt, text=True, capture_output=True
    )
    if proc.returncode != 0:
        print(f"⚠️ Échec pour «{text[:30]}…»\n", proc.stderr.strip())
        return ""
    response = proc.stdout.strip()
    print("=== RÉPONSE DU MODÈLE ===")
    print(response)

    return proc.stdout.strip()

# 5) Appliquer la traduction
df['summary_fr'] = df['summary'].astype(str).apply(translate_thematics)

# 6) Sauvegarder
df.to_excel(output_excel, index=False)
print("✅ Colonnes traduites ajoutées et fichier enregistré dans :", output_excel)

df.columns = df.columns.str.strip()

col_name = 'summary_fr'
if col_name not in df.columns:
    raise KeyError(f"La colonne '{col_name}' n’existe pas.")

texts = (
    df[col_name]
    .dropna()
    .astype(str)
    .str.strip()
    .loc[lambda s: s != ""]
    .tolist()
)
if not texts:
    raise ValueError(f"Aucun résumé trouvé dans '{col_name}'")

numbered = "\n".join(f"{i+1}. {t}" for i, t in enumerate(texts, 1))

# --- Construction du prompt
prompt = f"""\
Tu es un haut fonctionnaire chargé de produire un rapport synthétique sur une consultation concernant une réforme du code pénal.

Tu vas recevoir ci-dessous une liste numérotée contenant les résumés individuels des avis exprimés par chacune des parties prenantes concernant le sujet de consultation suivant :
« {col_name} »

{numbered}

Sur la base de ces résumés individuels, ta tâche consiste à produire une synthèse très succincte de l'opinion générale des parties prenantes sur le sujet, en suivant ces consignes strictes :

    1) Identifie une unique catégorie exprimant la tendance générale dominante parmi les avis (ex. consensus positif, consensus négatif, division, réserve générale, soutien conditionnel, etc.).
    2) Rédige une description concise explicitant clairement et précisément cette position générale, en mettant en évidence les points majeurs d'accord ou de désaccord mentionnés fréquemment par les parties prenantes.

Réponds sans en-tête, sans guillemets.
"""
print("=== PROMPT ENVOYÉ ===\n", prompt)

# --- Appel Ollama
proc = subprocess.run(
    ["ollama", "run", model_name],
    input=prompt,
    text=True,
    capture_output=True
)
if proc.returncode != 0:
    raise RuntimeError(f"Ollama erreur :\n{proc.stderr}")

response = proc.stdout.strip()
print("=== RÉPONSE DU MODÈLE ===\n", response)

# --- Insertion dans le DataFrame
if 'Global_Summary' in df.columns:
    df = df.drop(columns=['Global_Summary'])

insert_at = df.columns.get_loc(col_name) + 1
df.insert(insert_at, 'Global_Summary', "")
df.iat[0, insert_at] = response

# --- Sauvegarde
df.to_excel(input_excel, index=False)
print("✅ Colonne 'Global_Summary' ajoutée, réponse insérée en ligne 1.")

col_name = 'summary_fr'
if col_name not in df.columns:
    raise KeyError(f"La colonne '{col_name}' n’existe pas.")

texts = (
    df[col_name]
    .dropna()
    .astype(str)
    .str.strip()
    .loc[lambda s: s != ""]
    .tolist()
)
if not texts:
    raise ValueError(f"Aucun résumé trouvé dans '{col_name}'")

numbered = "\n".join(f"{i+1}. {t}" for i, t in enumerate(texts, 1))

# --- Construction du prompt
prompt = f"""\
Tu es un haut fonctionnaire chargé de produire un rapport synthétique sur une consultation concernant une réforme du code pénal.

Tu vas recevoir ci-dessous une liste numérotée contenant les résumés individuels des avis exprimés par chacune des parties prenantes concernant le sujet de consultation suivant :
« {col_name} »

{numbered}

Sur la base de ces résumés individuels, ta tâche consiste à produire une synthèse des justifications principales des parties prenantes sur le sujet, il faut que tu donnes les grandes raisons pourquoi les acteurs sont contre ou pour la réforme , formule ta réponse sous la forme d'une liste a puce.

Réponds sans en-tête, sans guillemets.
"""
print("=== PROMPT ENVOYÉ ===\n", prompt)

# --- Appel Ollama
proc = subprocess.run(
    ["ollama", "run", model_name],
    input=prompt,
    text=True,
    capture_output=True
)
if proc.returncode != 0:
    raise RuntimeError(f"Ollama erreur :\n{proc.stderr}")

response = proc.stdout.strip()
print("=== RÉPONSE DU MODÈLE ===\n", response)

# --- Insertion dans le DataFrame
if 'Position_Summary' in df.columns:
    df = df.drop(columns=['Position_Summary'])

insert_at = df.columns.get_loc(col_name) + 1
df.insert(insert_at, 'Position_Summary', "")
df.iat[0, insert_at] = response

# --- Sauvegarde
df.to_excel(input_excel, index=False)
print("✅ Colonne 'Position_Summary' ajoutée, réponse insérée en ligne 1.")